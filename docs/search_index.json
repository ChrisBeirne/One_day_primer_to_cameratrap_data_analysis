[["index.html", "An Primer to Camera Trap Data Management and Analysis in R Chapter 1 Introduction 1.1 How to use this book 1.2 Get in touch 1.3 Cite the course 1.4 Acknowledgements", " An Primer to Camera Trap Data Management and Analysis in R Christopher Beirne, the Wildlife Coexistence Lab, UBC, and the WildCam Network 2024-05-07 Chapter 1 Introduction This is an abridged version of the full three day course located here: An Introduction to Camera Trap Data Management and Analysis in R. That version will be the most up-to-date and comprehensive. 1.1 How to use this book You can run this code to get a quick flavour for camera trap data analyses and work flows. Download the example data via dropbox and ‘follow-along’ by cutting and pasting the code Important note The code chunks are color coded by their function: # Green chunks are essential code which must be copied and run in # R for the document to work When you hover over these colored chunks a ‘copy’ symbol will appear in the top right to transfer your code! ## [1] &quot;Gray code chucks are code output from R&quot; 1.2 Get in touch If you have any questions about this document and the information it contains, please email me or, better still, submit an issue on our the course GitHub page. 1.3 Cite the course If you would like to cite this primer, please use the citation for the full course: Beirne, C. &amp; Burton, C. (2022). An Introduction to Camera Trap Data Management and Analysis in R https://zenodo.org/doi/10.5281/zenodo.10524184 1.4 Acknowledgements This course was produced by Christopher Beirne, Cole Burton’s Wildlife Coexistence Lab at UBC, and the WildCAM Network. "],["prep.html", "Chapter 2 Preparing for the course 2.1 Install R 2.2 Install RStudio 2.3 Install the required packages 2.4 Create an R project 2.5 Download the data files 2.6 The example datasets 2.7 Practise before the course", " Chapter 2 Preparing for the course In order reproduce the data management and analysis examples detailed in this book, you will need to take the following steps. Install R Install R Studio Install associated R packages Create an R project Put the example data in the R project The steps to do this are outlined below: If you get stuck send me an email! 2.1 Install R Windows Click on this link and then Download R-4.4.0 for Windows. Mac Click on this link and then the R-4.4.0.pkgs link. If you already have R please update your R client so that it is on at least version 4.4.0. Checkout the installR package to this directly from the terminal. 2.2 Install RStudio Through the course we will use RStudio to interact with R. Please download RStudio Desktop (Free) from the RStudio website. Alternatives to RStudio exist and we are happy if you want to use one of those instead! Installation check Open RStudio. If all has gone well you should see something like this: 2.3 Install the required packages The next step is to install the packages required for the course. We need to do this in two steps: first, install packages which are on CRAN (the Comprehensive R Archive Network), and then install those which are not. Finally, we have provided the links to install and setup R Google Earth Engine (rgee). This is an optional step for advanced users only - we will not be using it in the course! 2.3.1 CRAN packages Copy and paste the following code into your R terminal and press enter. Note - if you hover over the code block a copy button appears in the top right. # A list of the required packages list.of.packages &lt;- c(&quot;activity&quot;, &quot;corrplot&quot;, &quot;cowplot&quot;, &quot;dplyr&quot;, &quot;elevatr&quot;, &quot;gfcanalysis&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;iNEXT&quot;, &quot;kableExtra&quot;, &quot;Hmsc&quot;, &quot;leaflet&quot;, &quot;lme4&quot;, &quot;lubridate&quot;, &quot;magrittr&quot;, &quot;MCMCvis&quot;, &quot;MODISTools&quot;, &quot;osmdata&quot;, &quot;pals&quot;, &quot;plotly&quot;, &quot;remotes&quot;, &quot;rmarkdown&quot;, &quot;sf&quot;, &quot;spOccupancy&quot;, &quot;stars&quot;, &quot;stringr&quot;, &quot;terra&quot;, &quot;tibble&quot;, &quot;tidyr&quot;, &quot;unmarked&quot;, &quot;viridis&quot;, &quot;jtools&quot;, &quot;vegan&quot;, &quot;MuMIn&quot;, &quot;rgdal&quot;, &quot;usedist&quot;, &quot;taxize&quot;) # A check to see which ones you have and which are missing new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] # Code which tells R to install the missing packages if(length(new.packages)) install.packages(new.packages) lapply(list.of.packages, require, character.only = TRUE) 2.3.2 Other packages Some packages must be compiled from sources other than CRAN. Copy and paste following code block into your R console and press enter. # We use the remotes package to access package repositories not on the # CRAN interface (e.g. on github) library(remotes) remotes::install_github(&quot;RS-eco/traitdata&quot;) remotes::install_github(&quot;arcaravaggi/remBoot&quot;) remotes::install_github(&quot;annam21/spaceNtime&quot;) 2.4 Create an R project If you do not already work within R projects - you should! It allows you to work on multiple projects at the same time, and makes specifying file paths much simpler. Finally, if you want to incorporate GiHub into your workflows in the future, the use of R Projects is essential! To create an R project for this course: Step 1 Click on File -&gt; New project Step 2 Click New Directory Step 3 Then click New Project Step 4 Give your project a name and choose a folder to save it in (you do not have to copy the options here): Step 5 Then click Create Project The best thing about R Projects is that all the files contained within it can be specified relative to the project folder - no more long file paths to deal with! Currently the ‘Files’ tab in the bottom right should be empty (aside from the .rproj file): Take note of the file path in the image above. For me it is C:/Users/Dropbox/wildco_R_course as this is where you will copy the data files to in later steps. You can also go straight to the root directory the project by clicking the three dots to the right of the file path in the Files tab! Next, lets download the data files we need for this course! 2.5 Download the data files Step 1 Click on the following dropbox link: Data Management and Analysis Files Step 2 Click download: Step 3 Extract the files (it doesn’t matter where to), then open the data_for_intro_to_camera_traps folder and copy the data folder it contains. Step 4 Then paste the data folder into your newly created R project folder. Step 5 If everything has worked, your `Files’ window in R Studio should now look like this: And you are ready for the course! 2.6 The example datasets If you navigate through data &gt; raw_data you will see that there are two files. One called example_data the other called your_data. They are summarised below: 2.6.1 example_data We have provided a subset of data derived from the WildCo Lab’s “Algar Restoration Project”. In the interest of teaching and code processing times, we have not provided a full dataset. Rather the data represent a sub-sample of sites (38 of 73 available) and years (2 of 4 available). If you want more information on this project, see the following papers (and the archived datasets they contain): Tattersall, E. R., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2020). Mammal seismic line use varies with restoration: Applying habitat restoration to species at risk conservation in a working landscape. Biological Conservation, 241, 108295. Tattersall, E. R., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2020). Boreal predator co‐occurrences reveal shared use of seismic lines in a working landscape. Ecology and Evolution, 10(3), 1678-1691. Beirne, C., Sun, C., Tattersall, E. R., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2021). Multispecies modelling reveals potential for habitat restoration to re‐establish boreal vertebrate community dynamics. Journal of Applied Ecology, 58(12), 2821-2832. Burton, A. C., Beirne, C., Sun, C., Granados, A., Procko, M., Chen, C., … &amp; Burgar, J. (2022). Behavioral “bycatch” from camera trap surveys yields insights on prey responses to human‐mediated predation risk. Ecology and evolution, 12(7), e9108. Sun, C., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2022). A cautionary tale comparing spatial count and partial identity models for estimating densities of threatened and unmarked populations. Global Ecology and Conservation, 38, e02268. Sun, C., Beirne, C., Burgar, J. M., Howey, T., Fisher, J. T., &amp; Burton, A. C. (2021). Simultaneous monitoring of vegetation dynamics and wildlife activity with camera traps to assess habitat change. Remote Sensing in Ecology and Conservation, 7(4), 666-684. 2.6.2 your_data The your_data folder contains files I have provided. This is the subset of an unpublished (and as yet un-analysed) dataset. I will leave it to you to find out more about it during the course! You can replace this data set with your own if you wish. If you want to use your own data it MUST be in ‘Wildlife Insights’ format - see the descriptions here and for a existing example/template see here. NOTE delete the description row if you are using your own data. The green/bolded columns shown in the template example are the absolute minimal essential columns - you can have more columns with other information! 2.7 Practise before the course Finally, if you want to practice your R skills before the course, here are two (of many) great resources out there: R Programming for Beginners | Complete Tutorial | R &amp; RStudio - Some great introductory videos to working in R Modern R with the tidyverse - A book introducing tidyverse data manipulation "],["preprocessing-and-labelling.html", "Chapter 3 Preprocessing and labelling 3.1 Data storage 3.2 Preprocessing 3.3 Labelling 3.4 End dates and outages", " Chapter 3 Preprocessing and labelling Once you have deployed your camera traps and brought your SD cards. We have several steps we need to perform before we can start analyzing the data: backup the data pre-process the files label the footage update deployment end dates We summarise each step below and point to useful tools where necessary. 3.1 Data storage The file structure of your data backups depends on the structure of your project. We use one of two different options, which each have their merits: 1) Location based This is likely the most intuitive method if you are manually sorting data or using an image labeller (software to manage your camera data) which uses the location as the key organizing element. You would make a folder using the ‘placename’ (unique location where a camera is deployed), then copy all of the data relating to that site within it (left). Note, if you had multiple camera deployments you would have nested folders with the ‘deployment_id’ as the name: 2) Deployment based Increasingly camera trap management platforms are ‘deployment’ driven rather than location based (e.g. Wildlife Insights). In this instance, the images are placed within a folder named with the deployment_id (the unique code corresponding to that deployment), typically within a single folder. In this scenario, we would have a folder called ‘to upload’ with all of the unique deployment folders within it. Then, once the folder has been upload to the platform, then the folder is moved to an “uploaded” folder: Crucially - make redundant copies to ensure you do not lose data. We make both local and cloud-based copies of our data sets. 3.2 Preprocessing The following steps represent optional elements to apply to your data. Whether you need them depends on your questions, the platform you are using to label your data, and the volume of images you will be processing. 3.2.1 Renaming When a camera takes images, it applies sequential names which are duplicated across cameras (e.g. RCNX0001, RCNX0002 etc). In the future, if files are accidentally moved it would be difficult (if not impossible) to trace them back their origin. One way to get around this is to rename every camera image with a unique code (e.g. placename_datetime) which will ensure that line of data you generate can be traced back to an image, regardless of how it is stored. We have created a tool which can be applied to folders of images organised by location and deployment, to create unique codes for each image:the WildCo Image Renamer. The repository has an example dataset which you can play around with to get familiar with the tool. 3.2.2 Automated Labelers Once you have backed up and renamed your images, you may want to process them with an Artificial Intelligence (AI) labeler. Although they are pretty cool and in vogue right now, the desicion to use one (or not) should be based on several points: - The number of image you have to process If you only have a small dataset (a few thousand images) it is likely easier to do manually - Whether there is an AI labeler validated for your study area and strata Despite the claims of their authors, AI labelers are not perfect. If they haven’t been validated in your survey location then use extreme caution when applying it. For example, an AI algorithm developed for terrestrial camera traps data will likely not work well on an arboreal dataset. - How much money you have For AI labelers to run quickly, you may need some very expensive computer gear or cloud computing time. Do not assume that this is cheaper than manual labor! - The resolution of the labels you require AI labelers are getting pretty good at sifting out blank images, but they have a long way to be before they can reliably split ground squirrel species (Urocitellus sp), or long-nosed armadillo species (Dasypus sp.)! For a very pragmatic and informed take on the current state of the art, see Saul Greenberg’s Automated Image Recognition for Wildlife Camera Traps: Making it Work for You. report. One of the biggest players in the game is undoubtedly Megadetector. Click the link for an overview of the machine learning model and how it might work for you. Finally, some platforms now have their own inbuilt labeling AI (e.g. Wildlife Insights), which is certainly much more accessible than developing your own. Our only advice is be weary of the identifications they generate and always check your data (a.k.a. keep a human in the loop - at least for now). 3.2.3 Sensitive images One of the benefits of AI labelers is you can use them to remove sensitive information (such as peoples identities) from images without ever looking at them. An example of this would be camera trapping in protected areas where it is not possible to ask every person if they are happy being photographed for science. Instead, we can use megadetector (or another AI labeler) to tell us when a human is detected in an image, then blur the area of that photo to remove individually identifying information. Previously researchers had to delete the human images to be compliant with privacy requirements - which throws away valuable data of human use. The WildCo lab has developed a tool to blur human images using Megadetector outputs: WildCo_Face_Blur. Click the link for details on how to use it. For a discussion of its application in a recreational ecology context see: Fennell, Mitchell, Christopher Beirne, and A. Cole Burton. “Use of object detection in camera trap image identification: Assessing a method to rapidly and accurately classify human and animal detections for research and application in recreation ecology.” Global Ecology and Conservation 35 (2022): e02104. 3.2.4 Timelapse extraction Timelapse photographs can be critical to determine when cameras are functioning, particularly in low productivity environments where wildlife detections are rare. We highly recommend you take a photo at noon each day! They can also be used to generate site-level vegetation indices, such as NDVI, as they are taken at the same time every day. However, you likely don’t want to be sort through thousands of images of leaves and grass, or if you want to extract the images to run through a different program (e.g. phenopix package - see the covariates chapter). To quickly extract timelapse images we develop some code which uses the metadata of the images to filter out timelapse photos from motion detected photos. It is packaged up as part of the WildCo_Image_renamer script. 3.3 Labelling We often get asked what the best software/data platform is for labeling images… and the pragmatic answer is that it does not matter as long as you export your data in a standardised format (see the data standardisation chapter. The truth is that different projects have different needs: If you have a poor internet connection you might need to use a standalone offline software, such as Timelapse Or if you work internationally with a large team of labelers who will tag images simultaneously, an online data platform, such as Wildlife Insights, might be essential Dan Morris has curated a fantastic list of currently available tools here: Everything I know about machine learning and camera traps. In a nutshell: Data platforms are web- and desktop-based tools used for efficient and standardized data management, sharing, and analysis of remote camera data. A number of platforms exist so it is important that users choose the one best suited to their needs. To help camera trap users make this decision, the Wildcam network has developed a comparison of different camera data platforms. It provides an overview of platforms and software used in remote camera research in western Canada. As software and online tools are often subject to frequent updates and change, we recognize this as a document subject to change over time. Click here to review the comparison (last updated June 2020). We welcome feedback at any time (info@wildcams.ca) Software are programs specifically designed for camera trap photos and their associated data is now recognized as the best method for data processing. There are quite a few programs available for practitioners, but many of them have most of the same functionalities. The relatively few unique features that distinguish programs will help to determine what software to use, and what features are needed for specific studies will vary depending on their study designs. See: Wearn, O. R. and P. Glover-Kapfer. 2017. Camera-trapping for conservation: a guide to best-practices. WWF conservation technology series 1.1 181. Young, S., J. Rode‐Margono and R. Amin. 2018. Software to facilitate and streamline camera trap data management: a review. Ecology and Evolution, 8: 9947-9957. 3.4 End dates and outages It is very important to note that camera deployments do not end when you pickup the camera - they end when the camera stops collecting comparable data. The best time to record date a camera stops functioning probably is when you are labeling images. Do not cut this corner! Below is the same camera station, at two points in time. The data from these are not comparable - if a tree fell on you whilst you were out counting animals you would probably count less effectively too! We would edit the deployment end to to reflect when it stopped recording comparable data (not all examples are as clear cut as this one). "],["standard.html", "Chapter 4 Metadata standardisation 4.1 The Wildlife Insights Minimum Metadata Standards", " Chapter 4 Metadata standardisation The images produced by camera traps alone are useless. We need to keep accurate records of how the data were collected, labelled, and manipulated if we are to achieve the goal of synthesizing data from multiple projects. Thus, metadata is simply “data that provides information about other data”. The benefits of ‘standardizing’ the metadata associated with camera traps, or other sensors of biodiversity, are hopefully clear - it should facilitate the rapid and robust exploration, analysis and sharing of information on wildlife populations. Ultimately resulting in more robust, repeatable, and timely research and management decisions. 4.1 The Wildlife Insights Minimum Metadata Standards The convention we use in this course is the data standards used by Wildlife Insights. Their standard format is composed of four different elements: Project data proj.csv a dataframe containing key information about the project itself, e.g. how the cameras were deployed and what the target features were. Image data img.csv a dataframe containing all of the information contained within each image. This information is typically added by humans, but increasing we are using artificial intelligence to speed up this process. Deployment data dep.csv a dataframe listing the activity of the camera traps involved in your study, and any issues encountered during deployments which may influence their analysis Camera data cam.csv a dataframe all the cameras deployed in the project Below we give a quick summary and explanation of each. First, read in the data files: pro &lt;- read.csv(&quot;data/raw_data/example_data/proj.csv&quot;, header=T) img &lt;- read.csv(&quot;data/raw_data/example_data/img.csv&quot;, header=T) dep &lt;- read.csv(&quot;data/raw_data/example_data/dep.csv&quot;, header=T) cam &lt;- read.csv(&quot;data/raw_data/example_data/cam.csv&quot;, header=T) Let’s look at each one in turn. 4.1.1 Project data The project files contains a general description of the project. It should give someone a helicopter overview of your project, and provide the data usage guidelines. project_id AlgarRestorationProject project_name AlgarRestorationProject project_short_name Algar project_objectives Investigate medium-large bodied mammal habitat use in response to human recreation spatially and temporally project_species NA project_species_individual NA project_sensor_layout Stratified project_sensor_layout_targeted_type Seismic lines project_bait_use No project_bait_type NA project_stratification Seismic line restoration treatements and controls project_stratification_type Offline, HumanUse project_sensor_method Sensor.Detection project_individual_animals NA project_blank_images yes project_sensor_cluster NA project_admin Cole Burton project_admin_email cole.burton@ubc.ca project_admin_organization University of British Columbia country_code NA embargo NA initiative_id NA metadata_license NA image_license NA data_citation Beirne, Christopher, Catherine Sun, Erin R. Tattersall, Joanna M. Burgar, Jason T. Fisher, and A. Cole Burton. Multispecies modelling reveals potential for habitat restoration to re‐establish boreal vertebrate community dynamics. Journal of Applied Ecology 58, no. 12 (2021): 2821-2832. count_optional no project_type image 4.1.2 Image data This file contains the image labels - what is in each picture and its properties. Each image you have processed is linked to at least one row in the detection data. Multiple rows may exist if there are multiple species in a camera trap image, or if you are identifying multiple unique individuals. project_id deployment_id image_id filename location is_blank identified_by wi_taxon_id class order family genus species common_name uncertainty timestamp number_of_objects age sex animal_recognizable individual_id individual_animal_notes behavior highlighted markings cv_confidence license placename group_size temperature AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-01.JPG Algar27__2018-04-13__13-51-01.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:01 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-02.JPG Algar27__2018-04-13__13-51-02.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:02 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-03.JPG Algar27__2018-04-13__13-51-03.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:03 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-06.JPG Algar27__2018-04-13__13-51-06.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:06 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-07.JPG Algar27__2018-04-13__13-51-07.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:07 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA AlgarRestorationProject ALG027_2018-04-11 Algar27__2018-04-13__13-51-09.JPG Algar27__2018-04-13__13-51-09.JPG NA 0 ERT NA Mammalia Carnivora Felidae Lynx canadensis NA NA 2018-04-13 13:51:09 1 Adult NA NA NA NA NA NA NA NA ALG027 1 NA 4.1.3 Deployment data This is the camera deployment data - where the deployment occurred, when it started, when it ended and other relevant information about each unique deployment. project_id deployment_id placename longitude latitude start_date end_date bait_type bait_description feature_type feature_type_methodology camera_id camera_name quiet_period camera_functioning sensor_height height_other sensor_orientation orientation_other plot_treatment plot_treatment_description detection_distance subproject_name subproject_design event_name event_description event_type recorded_by AlgarRestorationProject ALG027_2018-04-11 ALG027 -112.4735 56.33280 2018-04-11 2018-11-15 None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA AlgarRestorationProject ALG027_2018-11-15 ALG027 -112.4735 56.33280 2018-11-15 2019-04-03 None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA AlgarRestorationProject ALG027_2019-04-03 ALG027 -112.4735 56.33280 2019-04-03 NA None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA AlgarRestorationProject ALG029_2018-04-07 ALG029 -112.5483 56.39474 2018-04-07 2018-11-15 None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA AlgarRestorationProject ALG029_2018-11-15 ALG029 -112.5483 56.39474 2018-11-15 2019-04-02 None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA AlgarRestorationProject ALG029_2019-04-02 ALG029 -112.5483 56.39474 2019-04-02 2019-11-20 None NA HumanUse NA NA NA 1 Camera Functioning 100 NA NA NA NA NA NA Restoration NA NA NA NA NA 4.1.4 Camera inventory An inventory of all the cameras used in the project. Ideally, each camera would be represented in the deployment data. This technically isn’t 100% necessary to analyse your dataset, although there are some scenarios where it might help. project_id camera_id camera_name make model serial_number year_purchased AlgarRestorationProject 1 C0001 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 2 C0002 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 3 C0003 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 4 C0004 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 5 C0005 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 6 C0006 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 7 C0007 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 8 C0008 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 9 C0009 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 10 C0010 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 11 C0011 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 12 C0012 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 13 C0013 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 14 C0014 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 15 C0015 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 16 C0016 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 17 C0017 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 18 C0018 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 19 C0019 NA Reconyx Hyperfire 2 NA NA AlgarRestorationProject 20 C0020 NA Reconyx Hyperfire 2 NA NA 4.1.5 Important note These are simply the minimum sheets you require - we derive a lot of other useful data frames when moving from raw camera data to analyzable camera data. See the Creating analysis dataframes section for further examples. Further Reading Forrester, T. et al. An open standard for camera trap data. Biodivers. Data J. 4, (2016). Meek, P. D., et al. “Recommended guiding principles for reporting on camera trapping research.” Biodiversity and conservation 23.9 (2014) RISC Wildlife Camera Metadata Protocol "],["error-checking.html", "Chapter 5 Error checking 5.1 Standardised exploration script 5.2 Formatting dates 5.3 Basic trapping summaries 5.4 Error checks 5.5 Diel activity check 5.6 Conclusion", " Chapter 5 Error checking The most important part of analyzing camera trap data is checking and exploring your data! Based on the projects we have worked on synthesizing multiple datasets from different sources… camera trappers are not doing a very good job of checking for errors. Working in R makes it possible to rapidly check your data, ideally in almost real time as you collect it. In an ideal world it would be worth downloading the data for your project at least once per month and checking that ‘everything’ looks good. But what constitutes ‘everything’? 5.1 Standardised exploration script In the Wildlife Coexistence Lab developed a standardized R script to check the data generated by camera trap projects. This script is kept on our WildCO Single Site Exploration GitHub page. Below we run through the important elements of checking camera trap data, and where they is a coding skill fundamental to the process, we explore it in more detail (a.k.a. skill checks). Let’s go! First, open the .Rproj file your created in the course preparation section. Then click File -&gt; New file -&gt; Rscript (alternatively you can use the R Markdown option if you are comfortable with that) After the file has opened, immediately save it as ’01_example_error_checking_and_export.R`. We will usually make a new R sheet for each chapter - however the error checking and analysis data creation chapters should be in the same document. Second, read in our standardized example datasets: # Load your data sheets pro &lt;- read.csv(&quot;data/raw_data/example_data/proj.csv&quot;, header=T) img &lt;- read.csv(&quot;data/raw_data/example_data/img.csv&quot;, header=T) dep &lt;- read.csv(&quot;data/raw_data/example_data/dep.csv&quot;, header=T) cam &lt;- read.csv(&quot;data/raw_data/example_data/cam.csv&quot;, header=T) #Load Packages list.of.packages &lt;- c( &quot;leaflet&quot;, # creates interactive maps &quot;plotly&quot;, # creates interactive plots &quot;kableExtra&quot;, # Creates interactive tables &quot;tidyr&quot;, # A package for data manipulation &quot;dplyr&quot;, # A package for data manipulation &quot;viridis&quot;, # Generates colors for plots &quot;corrplot&quot;, # Plots pairwise correlations &quot;lubridate&quot;, # Easy manipulation of date objects &quot;taxize&quot;, # Package to check taxonomy &quot;sf&quot;) # Package for spatial data analysis # Check you have them in your library new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] # load them if(length(new.packages)) install.packages(new.packages,repos = &quot;http://cran.us.r-project.org&quot;) lapply(list.of.packages, require, character.only = TRUE) ## Loading required package: leaflet ## Loading required package: plotly ## Loading required package: ggplot2 ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout ## Loading required package: dplyr ## ## Attaching package: &#39;dplyr&#39; ## The following object is masked from &#39;package:kableExtra&#39;: ## ## group_rows ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union ## Loading required package: viridis ## Loading required package: viridisLite ## Loading required package: corrplot ## corrplot 0.92 loaded ## Loading required package: lubridate ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union ## Loading required package: taxize ## Loading required package: sf ## Linking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.3.1; sf_use_s2() is TRUE ## [[1]] ## [1] TRUE ## ## [[2]] ## [1] TRUE ## ## [[3]] ## [1] TRUE ## ## [[4]] ## [1] TRUE ## ## [[5]] ## [1] TRUE ## ## [[6]] ## [1] TRUE ## ## [[7]] ## [1] TRUE ## ## [[8]] ## [1] TRUE ## ## [[9]] ## [1] TRUE ## ## [[10]] ## [1] TRUE 5.2 Formatting dates Every aspect of camera trapping involves manipulating date objects - calculating how long cameras were active, when detections occurred, working with timezones etc. Thus, as a camera trapper working in R you need to be comfortable dealing with them. Fortunately the process has been made far easier with the lubridate package. The first dates we need to convert are those in the deployment (dep) datasheet - the start and end times of each period of camera activity. The way lubridate works is you specify the order of the days, months years, hours, minutes and seconds with the codes d,m,y,h,m, and s respectively. If you want to learn more about the amazing functionality of the ‘lubridate’ package - check out the Lubridate Cheatsheet 5.2.1 Deployment dates We use the ymd() function to convert our dates into date objects. Lets convert the date columns from character strings to date objects: # Format the deployment data dates # start dates dep$start_date &lt;- ymd(dep$start_date) # end dates dep$end_date &lt;- ymd(dep$end_date) # Make a new column called days - calculate thwe interval dep$days &lt;- interval(dep$start_date, dep$end_date)/ddays(1) We should then check the range of dates the cameras were active for. Things to look out for are: - 0’s A value of zero would mean a deployments which started and ended on the same day -&gt; it typically denotes a camera which malfunctioned instantly. - NA’s This is either an end_date which is NA e.g. if the camera was stolen, or it could be a date value which failed to parse e.g. if you had a typo in your date column such as ymd(\"202-212-24\") it would return NA - Negative numbers Are more common that you think… someone probably got the start and end dates the wrong way round when entering data. Lets look at the range of values we have: summary(dep$days) Note - a camera that was on a ‘HumanUse’ feature was stolen - so it is an NA! 5.2.2 Image dates We next need to convert the img$timestamp column to a date-object. We use the ‘ymd_hms()’ function to do this, as images have time data too. # Image dates # Convert the dates in your images labels to date objects img$timestamp &lt;- ymd_hms(img$timestamp) # Check it worked range(img$timestamp) ## [1] &quot;2018-04-08 04:22:13 UTC&quot; &quot;2019-12-16 12:41:43 UTC&quot; We have data from early 2018 to late 2019. 5.3 Basic trapping summaries Now that our camera trap data are loaded into R, we can very quickly find out summary information about the dataset. These can feed directly into the methods section of your report/paper. First let’s count the number of unique locations: # Summary of the data # Count the number of camera locations paste(length(unique(dep$placename)), &quot;locations&quot;); ## [1] &quot;38 locations&quot; paste(length(unique(dep$deployment_id)), &quot;deployments&quot;); ## [1] &quot;114 deployments&quot; paste(nrow(img), &quot;image labels&quot;); ## [1] &quot;15290 image labels&quot; paste(nrow(img[img$is_blank == TRUE,]), &quot;blanks&quot;) ## [1] &quot;2633 blanks&quot; 5.4 Error checks Lets start with the fundamental error checks required with a new data set: Camera locations Deployment date checks Image and deployment matching Taxonomy Diel time 5.4.1 Camera locations A common mistake in camera trap data sets is that the locations are not where they are supposed to be. The safest way to check your data is to plot them… preferably R! After synthesizing &gt;100 different projects from different data contributors for one project, we found ~20%(!) of submissions had a clear and obvious location errors (e.g. a camera station in the middle of the Atlantic). Don’t just take my word for it: (p.s. Mason is well worth a follow on Twitter ) 5.4.1.1 Basic Leaflet map m &lt;- leaflet() %&gt;% addProviderTiles(providers$Esri.WorldImagery) %&gt;% #Add Esri Wrold imagery addCircleMarkers( lng=dep$longitude, lat=dep$latitude, popup=paste(dep$placename)) # include a popup with the placename! m Zoom in - what can you tell me about where the stations are located? Can you spot any differences between the stations? Clue: look for lines on the landscape. These lines are linear features related to oil and gas exploration, some cameras are deployed on them, others away from them. 5.4.1.2 Making corrections As you can see, we have one deployment location that is a long way from the others. It almost looks like it belongs to another project?! Let’s take a look at all of the deployments from that location (ALG069): dep[dep$placename==&quot;ALG069&quot;,c(&quot;deployment_id&quot;, &quot;placename&quot;, &quot;longitude&quot;, &quot;latitude&quot;)] ## deployment_id placename longitude latitude ## 100 ALG069_2018-04-07 ALG069 -113.5075 56.49352 ## 101 ALG069_2018-11-14 ALG069 -112.5075 56.49352 ## 102 ALG069_2019-04-02 ALG069 -112.5075 56.49352 It looks like there is a typo in one of the coordinates: -112.5075 -&gt; -113.5075. Let’s correct it: dep$longitude[dep$placename==&quot;ALG069&quot;] &lt;- -112.5075 5.4.1.3 Advanced leaflet map We will need to check our correction has worked. Let’s also color camera locations based on their dep$feature_type, include them in the legend, and have their names show up when we click on them too! # First, set a single categorical variable of interest from station covariates for summary graphs. If you do not have an appropriate category use &quot;project_id&quot;. category &lt;- &quot;feature_type&quot; # We first convert this category to a factor with discrete levels dep[,category] &lt;- factor(dep[,category]) # then use the turbo() function to assign each level a color col.cat &lt;- turbo(length(levels(dep[,category]))) # then we apply it to the dataframe dep$colours &lt;- col.cat[dep[,category]] m &lt;- leaflet() %&gt;% addProviderTiles(providers$Esri.WorldImagery, group=&quot;Satellite&quot;) %&gt;% addTiles(group=&quot;Base&quot;) %&gt;% # Include a basemap option too addCircleMarkers(lng=dep$longitude, lat=dep$latitude, # Co lour the markers depending on the &#39;feature type&#39; color=dep$colours, # Add a popup of the placename and feature_type together popup=paste(dep$placename, dep[,category])) %&gt;% # Add a legend explaining what is going on addLegend(&quot;topleft&quot;, colors = col.cat, labels = levels(dep[,category]), title = category, labFormat = labelFormat(prefix = &quot;$&quot;), opacity = 1) %&gt;% # add a layer control box to toggle between the layers addLayersControl( baseGroups = c(&quot;Satellite&quot;, &quot;Base&quot;)) m If you click on a point you will see it’s corresponding placename and feature_type - so you can find the problem data. You can also check your treatment categories using the key. If you zoom in, all the “offline” locations should be &gt;100m away from a linear features, the other on top of them. For more examples of leaflet in R, see RStudio’s leaflet tutorial. Check the distance between camera pairs Sometimes the coordinates of a camera stations are accidentally repeated in the deployment data, which can actually be very hard to see on a map as the points will overlay perfectly. The way we check this is to calculate the pairwise distance between all of the unique deployments in the project. This helps us in two ways: we can find “cryptic” duplication events in the deployment coordinates this distance is often reported in manuscript method sections In the following code block we make first use of the simple features (sf) package - tools which make spatial operations which you would normally perform in ArcMap very easy (e.g. plotting and manipulating polygons). More on that later! # create a list of all the non-duplicated placenames camera_locs &lt;- dep %&gt;% dplyr::select(placename, latitude, longitude) %&gt;% unique() %&gt;% # remove duplicated rows (rows where the placename and coordinates match) st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = &quot;+proj=longlat&quot;) # Convert to `sf` format # Calculate the distances # distance matrix for all cameras camera_dist &lt;- st_distance(camera_locs) %&gt;% as.dist() %&gt;% usedist::dist_setNames(as.character(camera_locs$placename)) %&gt;% as.matrix() #Make temporary camera_dist_mins by converting diagonals/zeros to 999999 so we can avoid the zeros when using which.min function to find nearest cameras camera_dist_mins &lt;- camera_dist + diag(999999,dim(camera_dist)[1]) #Create new empty dataframe for appending results to camera_dist_list &lt;- data.frame(focal_cam = character(),nearest_cam = character(), dist = double()) #Cycle through each column of camera_dist_mins for (i in (1:dim(camera_dist_mins)[1])) { #Get index of minimum value of column i t &lt;- which.min(camera_dist_mins[,i]) #Combine relevant data into new_row new_row &lt;- data.frame(colnames(camera_dist_mins)[i],names(t),camera_dist_mins[t,i]) #Append the new_row to the accumulated results dataframe camera_dist_list[nrow(camera_dist_list) + 1,] = new_row } # Summarise the output summary(camera_dist_list$dist) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1103 1540 1978 2210 2578 5263 So the largest distance between two cameras is 5263m, the minimum is 1103m and on average it is 2210m. Again, put that straight into the methods section of your report/paper. 5.4.1.4 Do all images have a deployment associated with them? Another very useful check is to verify that all of the placenames have corresponding image data, and that all image data has corresponding deployment data! You would be surprised how often this is not the case! # check all check the placenames in images are represented in deployments # This code returns TRUE if it is and FALSE if it isn&#39;t. We can then summarize this with table() table(unique(img$placename) %in% unique(dep$placename)) ## ## TRUE ## 38 We have 38 TRUE’s, which means all the images have deployment data. Let’s check that all the placenames also have image data: # check all the placenames in deployments are represented in the images data table(unique(dep$placename) %in% unique(img$placename)) ## ## TRUE ## 38 Great. If you see any FALSE observations - you either have image data or deployments missing. Go back and check your raw data! 5.4.2 Camera activity checks The next step is to plot out the camera activity at each unique place name to see when our cameras are functioning. To make this plot we will need to use the plotly package for the first time. We use this because the plots are interactive, just like with leaflet we can zoom in and zoom out and find problem observations. It also dynamically changes the y-axis and x-axis labels to fit the data, which is very useful! See the Plotly graphing library for a wealth of options. 5.4.2.1 Camera activity summary In the following plot, black dots denote start and end dates, lines denote periods where a camera is active. Each unique placename gets its own row on the plot - you can hover over the lines to get the deployment_id. We will use a loop to build the different elements… you don’t need to understand the code itself, just how to interpret the output. Cut and paste the following: # Call the plot p &lt;- plot_ly() # We want a separate row for each &#39;placename&#39; - so lets turn it into a factor dep$placename &lt;- as.factor(dep$placename) # loop through each place name for(i in seq_along(levels(dep$placename))) { #Subset the data to just that placename tmp &lt;- dep[dep$placename==levels(dep$placename)[i],] # Order by date tmp &lt;- tmp[order(tmp$start_date),] # Loop through each deployment at that placename for(j in 1:nrow(tmp)) { # Add a line to &#39;p&#39; p &lt;- add_trace(p, #Use the start and end date as x coordinates x = c(tmp$start_date[j], tmp$end_date[j]), #Use the counter for the y coordinates y = c(i,i), # State the type of chart type=&quot;scatter&quot;, # make a line that also has points mode = &quot;lines+markers&quot;, # Add the deployment ID as hover text hovertext=tmp$deployment_id[j], # Color it all black color=I(&quot;black&quot;), # Suppress the legend showlegend = FALSE) } } # Add a categorical y axis p &lt;- p %&gt;% layout(yaxis = list( ticktext = as.list(levels(dep$placename)), tickvals = as.list(1:length(levels(dep$placename))), tickmode = &quot;array&quot;)) p What do the gaps signify? The breaks in the line signify periods when the camera at a location was not active. You can see there was a point in 2018 when 9 out of 38 cameras had stopped working. Can you see any issues? Yes! Sometimes you will see a deployment a long way to the left or right of the plot, this is usually a date error (e.g. ALG036). 5.4.2.2 Corrections We checked the original datasheets for ALG036 and found out that the deployment end date for ALG036_2019-04-04 was incorrectly entered. It was written as 2020 not 2019. Let’s correct it: dep$end_date[dep$deployment_id==&quot;ALG036_2019-04-04&quot;] &lt;- ymd(&quot;2019-11-21&quot;) #remember to format it as a date object 5.4.3 Detection check Once we are happy that are cameras were functioning when we expected them to be, we now need to check if all of our labelled images fall within the associated deployment periods. To do this we build on the previous plot above, but also add in the image data over the top. This plot can get very messy, so we divide it into sections of ten deployments. As before, black lines show an active camera. Red dots show an image detections at that time. We only show the output of the first 10 deployments, but you should do this for every single deployment you have! Note - the code below is complex, you don’t have to understand it all unless you want to # Make a separate plot for each 20 stations For each 20 stations # To do this make a plot dataframe tmp &lt;- data.frame(&quot;deployment_id&quot;=unique(dep$deployment_id), &quot;plot_group&quot;=ceiling(1:length(unique(dep$deployment_id))/20)) dep_tmp &lt;- left_join(dep,tmp, by=&quot;deployment_id&quot;) for(i in 1:max(dep_tmp$plot_group)) { # Call the plot p &lt;- plot_ly() #Subset the data to just that placename tmp &lt;- dep_tmp[dep_tmp$plot_group==i,] # Order by placename tmp &lt;- tmp[order(tmp$placename),] # Loop through each deployment at that placename for(j in 1:nrow(tmp)) { #Subset the image data tmp_img &lt;- img[img$deployment_id==tmp$deployment_id[j],] if(nrow(tmp_img)&gt;0) { p &lt;- add_trace(p, #Use the start and end date as x coordinates x = c(tmp_img$timestamp), #Use the counter for the y coordinates y = rep(j, nrow(tmp_img)), # State the type of chart type=&quot;scatter&quot;, # make a line that also has points mode = &quot;markers&quot;, # Add the deployment ID as hover text hovertext=paste(tmp_img$genus,tmp_img$species), # Color it all black marker = list(color = &quot;red&quot;), # Suppress the legend showlegend = FALSE) } # Add a line to &#39;p&#39; p &lt;- add_trace(p, #Use the start and end date as x coordinates x = c(tmp$start_date[j], tmp$end_date[j]), #Use the counter for the y coordinates y = c(j,j), # State the type of chart type=&quot;scatter&quot;, # make a line that also has points mode = &quot;lines&quot;, # Add the deployment ID as hover text hovertext=tmp$deployment_id[j], # Color it all black color=I(&quot;black&quot;), # Suppress the legend showlegend = FALSE) } # Add custom y axis labels p &lt;- p %&gt;% layout(yaxis = list( ticktext = as.list(tmp$deployment_id), tickvals = as.list(1:nrow(tmp)), tickmode = &quot;array&quot;)) print(p) } What would a problem look like? If you have images (red dots) occurring outside a period of camera activity - that would indicate a miss-match between the deployment data and the image data. You would need to revisit your datasheets to see where this mismatch occurred. If the error is in the deployment dates - correct them as above! If the error is in the image metadata (i.e. camera was set to the wrong date), you have several options: If you are working in a platform like Wildlife Insights there is a date-time frameshift correction you can perform: see The correcting timestamps section You can correct the underlying exif data of the images using EXIF date changer Finally, you could change the dates in R using lubridate. If you look at the deployment ALG029_2019-04-02 you will see that has what has happened here. We checked the datasheets and realised that the camera’s timestamp was set to the incorrect month when the deployment began (2019-05-02 instead of 2019-04-02). # We set the wrong date for the camera collecting images in deployment #&quot;:&quot;ALG029_2019-04-02&quot; # We established that the deployment was 30 days out (as there are 30 days in April) # So we add 30 days to all of the images in that deployment. img[img$deployment_id==&quot;ALG029_2019-04-02&quot;,]$timestamp &lt;- img[img$deployment_id==&quot;ALG029_2019-04-02&quot;,]$timestamp - days(30) # Easy! You should repeat the plot above to check it has worked! 5.4.4 Taxonomy check Dealing with taxonomy in camera trap data sets can be a nightmare, particularly if your data labeling software does not give standardized lists of species (e.g. you are manually sorting images into folders). A species list is also something which is often produced for the appendix of a report or paper. Let us start with building a list of our taxonomic classifications: # First define vector of the headings you want to see (we will use this trick a lot later on) taxonomy_headings &lt;- c(&quot;class&quot;, &quot;order&quot;, &quot;family&quot;, &quot;genus&quot;, &quot;species&quot;, &quot;common_name&quot;) # Subset the image data to just those columns tmp&lt;- img[,colnames(img)%in% taxonomy_headings] # Remove duplicates tmp &lt;- tmp[duplicated(tmp)==F,] # Create an ordered species list sp_list &lt;- tmp[order(tmp$class, tmp$order, tmp$family, tmp$genus, tmp$species),] # Create a column to the species list with genus and species pasted together sp_list$sp &lt;- paste(sp_list$genus, sp_list$species, sep=&quot;.&quot;) # View the species list using kableExtra sp_list %&gt;% kbl(row.names=F) %&gt;% kable_styling(full_width = T) %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;250px&quot;) class order family genus species common_name sp Aves Galliformes Phasianidae Tympanuchus phasianellus NA Tympanuchus.phasianellus Aves Gruiformes Gruidae Grus canadensis NA Grus.canadensis Aves Passeriformes Corvidae Corvus corax NA Corvus.corax Aves Passeriformes Corvidae Perisoreus canadensis NA Perisoreus.canadensis Aves Strigiformes Strigidae Strix nebulosa NA Strix.nebulosa Mammalia Artiodactyla Cervidae Alces alces NA Alces.alces Mammalia Artiodactyla Cervidae Cervus canadensis NA Cervus.canadensis Mammalia Artiodactyla Cervidae Odocoileus virginianus NA Odocoileus.virginianus Mammalia Artiodactyla Cervidae Rangifer tarandus NA Rangifer.tarandus Mammalia Carnivora Canidae Canis latrans NA Canis.latrans Mammalia Carnivora Canidae Canis lupus NA Canis.lupus Mammalia Carnivora Canidae Vulpes vulpes NA Vulpes.vulpes Mammalia Carnivora Felidae Lynx canadensis NA Lynx.canadensis Mammalia Carnivora Mustelidae Lontra canadensis NA Lontra.canadensis Mammalia Carnivora Mustelidae Martes americana NA Martes.americana Mammalia Carnivora Ursidae Ursus americanus NA Ursus.americanus Mammalia Lagomorpha Leporidae Lepus americanus NA Lepus.americanus Mammalia Lagomorpha Leporidae Oryctolagus cuniculus NA Oryctolagus.cuniculus Mammalia Primates Hominidae Homo sapiens NA Homo.sapiens Mammalia Rodentia Sciuridae Tamiasciurus hudsonicus NA Tamiasciurus.hudsonicus NA NA NA blank NA .blank NA NA NA spp. NA .spp. NA NA NA Canachites canadensis NA Canachites.canadensis NA NA NA Unknown unknown NA Unknown.unknown NA NA NA Weasel spp. NA Weasel.spp. We have an external list of common names which we will use to update our species list and img file. # Import the dataframe tmp &lt;- read.csv(&quot;data/raw_data/example_data/common_names.csv&quot;) # Join it with the existing species list to add common names sp_list$common_name &lt;- NULL sp_list &lt;- left_join(sp_list, tmp) # And save the file write.csv(sp_list, paste0(&quot;data/raw_data/&quot;,pro$project_id[1],&quot;_raw_species_list.csv&quot;)) # Update the common names in the image data too # first remove the existing common_name column img$common_name &lt;- NULL # add an sp column to the img dataframe - remember the genus and species columns are not pasted together yet img$sp &lt;- paste(img$genus, img$species, sep=&quot;.&quot;) # Next we do the &#39;left_join&#39; img &lt;- left_join(img, sp_list[, c(&quot;sp&quot;, &quot;common_name&quot;)], by=&quot;sp&quot;) 5.5 Diel activity check Sometimes when setting up a camera trap, you can input the time incorrectly. This is actually very hard to detect unless you happen to be looking for it. The way we check is to plot the detections for each species by the 24 hour clock. If were get detections of nocturnal species in the day, or vice versa, it suggests there may be a problem. Caveat A diurnal species active at night doesn’t mean there is actually a problem, camera traps have revealed that many animals are active when we thought they were not! Cool note Researchers are increasingly using this information to determine a species “availability” for detection! More on that in the density and activity chapters. For any species detected more than 10 times, we will plot when they were detected: # First lets convert our timestamp to decimal hours img$hours &lt;- hour(img$timestamp) + minute(img$timestamp)/60 + second(img$timestamp)/(60*60) # Count all of the captures tmp &lt;- img %&gt;% group_by(common_name) %&gt;% summarize(count=n()) yform &lt;- list(categoryorder = &quot;array&quot;, categoryarray = tmp$common_name) fig &lt;- plot_ly(x = img$hours, y = img$common_name,type=&quot;scatter&quot;, height=1000, text=img$deployment_id, hoverinfo=&#39;text&#39;, mode = &#39;markers&#39;, marker = list(size = 5, color = &#39;rgba(50, 100, 255, .2)&#39;, line = list(color = &#39;rgba(0, 0, 0, 0)&#39;, width = 0))) %&gt;% layout(yaxis = yform) fig # Remove the column img$hours &lt;- NULL Can you see any exclusively diurnal species? Sandhill crane would be a good candidate. They are very rarely detected at night. Can you see any exclusively nocturnal species? Snowshoe hare! More on activity data in the Activity chapter 5.6 Conclusion Congratulations - you have thoroughly error checked your camera data! We may find more errors in the data exploration chapter, so stay vigilant. "],["data-creation.html", "Chapter 6 Analysis data creation 6.1 Common analysis data formats 6.2 Independent detections 6.3 Effort look-up 6.4 Observations by time interval 6.5 Our data 6.6 Creating analysis dataframes", " Chapter 6 Analysis data creation 6.1 Common analysis data formats Although the types of analysis you can perform on camera trap data vary markedly, they often depend on three key dataframe structures. We introduce these structures here, then show you how to apply them in subsequent chapters. 6.2 Independent detections The independent detections dataframe is the work horse of the vast majority of camera trap analyses, it is from this that you build the rest of your data frames. The threshold we use for determining what is an “independent detection” is typically 30 minutes… because camera trappers are creatures of habit! If you want to dig a little deeper it to the why, there is a nice summary in Rahel Sollmans “A gentle introduction to camera‐trap data analysis”: Researchers have used different thresholds, typically 30 min (e.g., O’Brien, Kinnaird, &amp; Wibisono, 2003) to an hour (Bahaa‐el‐din et al., 2016); some researchers have argued that multiple pictures within the same day may not represent independent detections (Royle, Nichols, Karanth, &amp; Gopalaswamy, 2009). In most cases, this threshold is determined subjectively, based on the best available knowledge of the species under study. But it can also be determined based on the temporal autocorrelation (Kays &amp; Parsons, 2014) or analysis of time intervals (Yasuda, 2004) of subsequent pictures. Independent data has a single row for each independent event: 6.3 Effort look-up Image data without effort data is worthless! There are lots of instances where you need to know which stations were operating on a given day. Some people like to store this information in a site x date matrix, but they are actually not that easy to data wrangle with. A long data frame with a site and date column is the most flexible (and keeps the dates in their native POSIX formats). Effort lookups have a single row for ever day a given location has an active camera: 6.4 Observations by time interval We saved the most useful data format until last! A site, time interval, effort, and species detection dataframe integrates the independent data and daily lookup described above. You can use it to create detection rates, occupancy data frames and much more (see the subsequent chapters)! We export yearly, monthly, weekly and daily data frames from our single site exploration script - which should cover you for much of what you want to do. We include two different types of response terms: Observations = the number of independent detections per time interval Counts = sum of the independent minimum group sizes per time interval Example of an observation by time matrix: Let’s build these data frames from our example_data! 6.5 Our data First, lets create the folder to store our data! dir.create(&quot;data/processed_data&quot;) This section will follow the following steps: Filter to our target species Create a camera activity look-up Determine our “independent detections” Create our analysis data frames 6.5.1 Filter to target species # Remove observations without animals detected, where we don&#39;t know the species, and non-mammals img_sub &lt;- img %&gt;% filter(is_blank==0, # Remove the blanks is.na(img$species)==FALSE, # Remove classifications which don&#39;t have species class==&quot;Mammalia&quot;, # Subset to mammals species!=&quot;sapiens&quot;) # Subset to anything that isn&#39;t human This has resulted in the removal of 33.2% of the observations. Which are composed of the following species: img_sub %&gt;% group_by(common_name) %&gt;% summarize(n()) ## # A tibble: 14 × 2 ## common_name `n()` ## &lt;chr&gt; &lt;int&gt; ## 1 american marten 41 ## 2 black bear 1331 ## 3 canada lynx 140 ## 4 caribou 787 ## 5 coyote 21 ## 6 elk 6 ## 7 gray wolf 352 ## 8 moose 2038 ## 9 rabbit 9 ## 10 red fox 39 ## 11 red squirrel 34 ## 12 river otter 2 ## 13 snowshoe hare 629 ## 14 white-tailed deer 4790 6.5.2 Create a daily camera activity lookup Next we create the daily camera activity look up (remember, one row for every day a camera is active). # Remove any deployments without end dates tmp &lt;- dep[is.na(dep$end_date)==F,] # Create an empty list to store our days daily_lookup &lt;- list() # Loop through the deployment dataframe and create a row for every day the camera is active for(i in 1:nrow(tmp)) { if(ymd(tmp$start_date[i])!=ymd(tmp$end_date[i])) { daily_lookup[[i]] &lt;- data.frame(&quot;date&quot;=seq(ymd(tmp$start_date[i]), ymd(tmp$end_date[i]), by=&quot;days&quot;), &quot;placename&quot;=tmp$placename[i]) } } # Merge the lists into a dataframe row_lookup &lt;- bind_rows(daily_lookup) # Remove duplicates - when start and end days are the same for successive deployments row_lookup &lt;- row_lookup[duplicated(row_lookup)==F,] 6.5.3 Determine ‘independent’ camera detections We rarely analyse raw camera data, rather we filter out multiple detections of the same individual within a given event. This is called creating and “independent detections” dataframe. As stated above, it is wise to think about what you are analyzing and whether such a threshold is appropriate. For example, if your organism of interest is very abundant, for examples human hikers on a busy trail, then using a 30 minute threshold may mean that multiple independent groups of hikers are rolled into a single, huge, “event”. # Set the &quot;independence&quot; interval in minutes independent &lt;- 30 # Specify what style of group count you want to include (if you have this data) # We will use group_size img_sub$animal_count &lt;- img_sub$group_size We will now break down the algorithm into subsections to make it clear what is occurring: Order the dataframe by deployment code and species img_tmp &lt;- img_sub %&gt;% arrange(deployment_id) %&gt;% # Order by deployment_id group_by(deployment_id, sp) %&gt;% # Group species together mutate(duration = int_length(timestamp %--% lag(timestamp))) # Calculate the gap between successive detections Determine independence of images If subsequent detections occur outside of the independence threshold, assign it a unique ID code. library(stringr) # Give a random value to all cells img_tmp$event_id &lt;- 9999 # Create a counter counter &lt;- 1 # Make a unique code that has one more zero than rows in your dataframe num_code &lt;- as.numeric(paste0(nrow(img_sub),0)) # Loop through img_tmp - if gap is greater than the threshold -&gt; give it a new event ID for (i in 2:nrow(img_tmp)) { img_tmp$event_id[i-1] &lt;- paste0(&quot;E&quot;, str_pad(counter, nchar(num_code), pad = &quot;0&quot;)) if(is.na(img_tmp$duration[i]) | abs(img_tmp$duration[i]) &gt; (independent * 60)) { counter &lt;- counter + 1 } } # Update the information for the last row - the loop above always updates the previous row... leaving the last row unchanged # group ID for the last row if(img_tmp$duration[nrow(img_tmp)] &lt; (independent * 60)| is.na(img_tmp$duration[nrow(img_tmp)])){ img_tmp$event_id[nrow(img_tmp)] &lt;- img_tmp$event_id[nrow(img_tmp)-1] } else{ counter &lt;- counter + 1 img_tmp$event_id[nrow(img_tmp)] &lt;- paste0(&quot;E&quot;, str_pad(counter, nchar(num_code), pad = &quot;0&quot;)) } # remove the duration column img_tmp$duration &lt;- NULL 6.5.4 Add additional data We could stop there, however there is other information we might light to extract about each individual event: the maximum number objects detected in an event how long the event lasts how many images are in each event # find out the last and the first of the time in the group top &lt;- img_tmp %&gt;% group_by(event_id) %&gt;% top_n(1,timestamp) %&gt;% dplyr::select(event_id, timestamp) bot &lt;- img_tmp %&gt;% group_by(event_id) %&gt;% top_n(-1,timestamp) %&gt;% dplyr::select(event_id, timestamp) names(bot)[2] &lt;- c(&quot;timestamp_end&quot;) img_num &lt;- img_tmp %&gt;% group_by(event_id) %&gt;% summarise(event_observations=n()) # number of images in the event event_grp &lt;- img_tmp %&gt;% group_by(event_id) %&gt;% summarise(event_groupsize=max(animal_count)) # calculate the duration and add the other elements diff &lt;- top %&gt;% left_join(bot, by=&quot;event_id&quot;) %&gt;% mutate(event_duration=abs(int_length(timestamp %--% timestamp_end))) %&gt;% left_join(event_grp, by=&quot;event_id&quot;)%&gt;% left_join(img_num, by=&quot;event_id&quot;) # Remove columns you don&#39;t need diff$timestamp &lt;-NULL diff$timestamp_end &lt;-NULL # remove duplicates diff &lt;- diff[duplicated(diff)==F,] # Merge the img_tmp with the event data img_tmp &lt;- img_tmp %&gt;% left_join(diff,by=&quot;event_id&quot;) Finally lets subset to the first row of each event to create our independent dataframe! # Remove duplicates ind_dat &lt;- img_tmp[duplicated(img_tmp$event_id)==F,] Next we remove any detections which occur outside of our known camera activity periods: # Make a unique code for ever day and deployment where cameras were functioning tmp &lt;- paste(row_lookup$date, row_lookup$placename) #Subset ind_dat to data that matches the unique codes ind_dat &lt;- ind_dat[paste(substr(ind_dat$timestamp,1,10), ind_dat$placename) %in% tmp, ] As a final step, we make the species column a ‘factor’ - this makes all the data frame building operations much simpler: ind_dat$sp &lt;- as.factor(ind_dat$sp) And we are ready to build our dataframes! 6.6 Creating analysis dataframes Finally, this script outputs 11 useful data frames for future data analysis: 1. A data frame of “independent detections” at the 30 minute threshold you specified at the start: “data/processed_data/AlgarRestorationProject_30min_Independent.csv” write.csv(ind_dat, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_detections.csv&quot;), row.names = F) # also write the cleaned all detections file (some activity analyses require it) write.csv(img_tmp, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_raw_detections.csv&quot;), row.names = F) 2. The “daily_lookup” which is a dataframe of all days a given camera station was active. Some people use an lookup matrix for this step, but we find the long format is much easier to use in downstream analysis. - “data/processed_data/_daily_deport_lookup.csv” write.csv(row_lookup, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_daily_lookup.csv&quot;), row.names = F) 3. Unique camera locations list: When we start to build the covariates for data analysis, it is very useful to have a list of your final project’s camera locations. We create this below in a simplified form. You can include any columns which will be use for data analysis, and export it. #Subset the columns tmp &lt;- dep[, c(&quot;project_id&quot;, &quot;placename&quot;, &quot;longitude&quot;, &quot;latitude&quot;, &quot;feature_type&quot;)] # Remove duplicated rows tmp&lt;- tmp[duplicated(tmp)==F,] # write the file write.csv(tmp, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_camera_locations.csv&quot;), row.names = F) 4. Final species list We also want to create a final species list. We subset the data to just those included in the independent data, and then save the file. tmp &lt;- sp_list[sp_list$sp %in% ind_dat$sp,] # Remove the &#39;verified&#39; column tmp$verified &lt;- NULL # We will replace the spaces in the species names with dots, this will make things easier for us later (as column headings with spaces in are annoying). library(stringr) tmp$sp &lt;- str_replace(tmp$sp, &quot; &quot;, &quot;.&quot;) write.csv(tmp, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_species_list.csv&quot;), row.names = F) 5 &amp; 6: A ‘site x species’ matrix of the number of independent detections and species counts across the full study period: “data/processed_data/AlgarRestorationProject_30min_Independent_total_observations.csv” “data/processed_data/AlgarRestorationProject_30min_Independent_total_counts.csv” # Total counts # Station / Month / deport / Species tmp &lt;- row_lookup # Calculate the number of days at each site total_obs &lt;- tmp %&gt;% group_by(placename) %&gt;% summarise(days = n()) # Convert to a data frame total_obs &lt;- as.data.frame(total_obs) # Add columns for each species total_obs[, levels(ind_dat$sp)] &lt;- NA # Duplicate for counts total_count &lt;- total_obs # Test counter i &lt;-1 # For each station, count the number of individuals/observations for(i in 1:nrow(total_obs)) { tmp &lt;- ind_dat[ind_dat$placename==total_obs$placename[i],] tmp_stats &lt;- tmp %&gt;% group_by(sp, .drop=F) %&gt;% summarise(obs=n(), count=sum(animal_count)) total_obs[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$obs total_count[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$count } # Save them write.csv(total_obs, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_total_observations.csv&quot;), row.names = F) write.csv(total_count, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_total_counts.csv&quot;), row.names = F) 7 &amp; 8: A ‘site_month x species’ matrix of the number of independent detections and species counts across for each month in the study period: “data/processed_data/AlgarRestorationProject_30min_Monthly_total_observations.csv” “data/processed_data/AlgarRestorationProject_30min_Monthly_total_counts.csv” # Monthly counts # Station / Month / days / Covariates / Species tmp &lt;- row_lookup # Simplify the date to monthly tmp$date &lt;- substr(tmp$date,1,7) # Calculate the number of days in each month mon_obs &lt;- tmp %&gt;% group_by(placename,date ) %&gt;% summarise(days = n()) # Convert to a data frame mon_obs &lt;- as.data.frame(mon_obs) mon_obs[, levels(ind_dat$sp)] &lt;- NA mon_count &lt;- mon_obs # For each month, count the number of individuals/observations for(i in 1:nrow(mon_obs)) { tmp &lt;- ind_dat[ind_dat$placename==mon_obs$placename[i] &amp; substr(ind_dat$timestamp,1,7)== mon_obs$date[i],] tmp_stats &lt;- tmp %&gt;% group_by(sp, .drop=F) %&gt;% summarise(obs=n(), count=sum(animal_count)) mon_obs[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$obs mon_count[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$count } write.csv(mon_obs, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_monthly_observations.csv&quot;), row.names = F) write.csv(mon_count, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_monthly_counts.csv&quot;), row.names = F) 9 &amp; 10: A ‘site_week x species’ matrix of the number of independent detections and species counts across for each week in the study period: “data/processed_data/AlgarRestorationProject_30min_Weekly_total_observations.csv” “data/processed_data/AlgarRestorationProject_30min_Weekly_total_counts.csv” # Weekly format # Station / Month / days / Covariates / Species tmp &lt;- row_lookup # Simplify the date to year-week tmp$date &lt;- strftime(tmp$date, format = &quot;%Y-W%U&quot;) # The way this is coded is the counter W01 starts at the first Sunday of the year, everything before that is W00. Weeks do not roll across years. # Calculate the number of days in each week week_obs &lt;- tmp %&gt;% group_by(placename,date ) %&gt;% summarise(days = n()) # Convert to a data frame week_obs &lt;- as.data.frame(week_obs) # Add species columns week_obs[, levels(ind_dat$sp)] &lt;- NA # Duplicate for counts week_count &lt;- week_obs # For each week, count the number of individuals/observations for(i in 1:nrow(week_obs)) { tmp &lt;- ind_dat[ind_dat$placename==week_obs$placename[i] &amp; strftime(ind_dat$timestamp, format = &quot;%Y-W%U&quot;)== week_obs$date[i],] tmp_stats &lt;- tmp %&gt;% group_by(sp, .drop=F) %&gt;% summarise(obs=n(), count=sum(animal_count)) week_obs[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$obs week_count[i,as.character(tmp_stats$sp)] &lt;- tmp_stats$count } write.csv(week_obs, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_weekly_observations.csv&quot;), row.names = F) write.csv(week_count, paste0(&quot;data/processed_data/&quot;,ind_dat$project_id[1], &quot;_&quot;,independent ,&quot;min_independent_weekly_counts.csv&quot;), row.names = F) For a site by day code example, see the full course: An Introduction to Camera Trap Data Management and Analysis in R 6.6.1 Final data check Finally, as a last check that our code is creating robust analysis data frames, we check if the observations/counts are the same across each temporal scale (total/monthly/weekly/daily). Check this using the following tables. Observations tmp &lt;- cbind(data.frame(&quot;Time&quot;=c(&quot;Total&quot;, &quot;Monthly&quot;, &quot;Weekly&quot;)), rbind(colSums(total_obs[,2:ncol(total_obs)]), colSums(mon_obs[,3:ncol(mon_obs)]), colSums(week_obs[,3:ncol(week_obs)]))) tmp %&gt;% kbl() %&gt;% kable_styling(full_width = T) %&gt;% column_spec(1, bold = T, border_right = T)%&gt;% kableExtra::scroll_box(width = &quot;100%&quot;) Time days Alces.alces Canis.latrans Canis.lupus Cervus.canadensis Lepus.americanus Lontra.canadensis Lynx.canadensis Martes.americana Odocoileus.virginianus Oryctolagus.cuniculus Rangifer.tarandus Tamiasciurus.hudsonicus Ursus.americanus Vulpes.vulpes Total 20350 176 8 93 1 241 1 52 24 562 2 119 26 228 10 Monthly 20350 176 8 93 1 241 1 52 24 562 2 119 26 228 10 Weekly 20350 176 8 93 1 241 1 52 24 562 2 119 26 228 10 Counts tmp &lt;- cbind(data.frame(&quot;Time&quot;=c(&quot;Total&quot;, &quot;Monthly&quot;, &quot;Weekly&quot;)), rbind(colSums(total_count[,2:ncol(total_count)]), colSums(mon_count[,3:ncol(mon_count)]), colSums(week_count[,3:ncol(week_count)]) )) tmp %&gt;% kbl() %&gt;% kable_styling(full_width = T) %&gt;% column_spec(1, bold = T, border_right = T)%&gt;% kableExtra::scroll_box(width = &quot;100%&quot;) Time days Alces.alces Canis.latrans Canis.lupus Cervus.canadensis Lepus.americanus Lontra.canadensis Lynx.canadensis Martes.americana Odocoileus.virginianus Oryctolagus.cuniculus Rangifer.tarandus Tamiasciurus.hudsonicus Ursus.americanus Vulpes.vulpes Total 20350 227 8 133 1 244 1 53 24 678 2 159 26 256 10 Monthly 20350 227 8 133 1 244 1 53 24 678 2 159 26 256 10 Weekly 20350 227 8 133 1 244 1 53 24 678 2 159 26 256 10 "],["covariates.html", "Chapter 7 Analysis covariates 7.1 Camera station covariates 7.2 Convert and save your covariates 7.3 Correlations between predictors", " Chapter 7 Analysis covariates Once we have created the building blocks for our data analysis dataframes, we must bring in the variables which will be used in the modelling steps. It is important to not that there are millions of ways to add covariates - both in terms of how you do it, and where you derive the data from. The covariates you use will depend on the questions you have, and the context of your survey. The examples provided here are not comprehensive and serve only as a guide! Create a new .R script Call it 02_example_covariates.R. Load the required packages and read in the locations dataframe library(kableExtra);library(dplyr); library(sf); library(MODISTools); library(lubridate); library(corrplot); library(terra); library(osmdata); library(elevatr) # Locations data frame locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations.csv&quot;, header=T) 7.1 Camera station covariates It is common to have a suite of covariates which you would like to investigate the effects of in your datasets. These could take the form of habitat designations or treatment types. These may already be included with your deployment data, or you may need to derive them from a variety of remote sources. In their simplest form, these variable are time invariant (they do not change), however you may have variables which change through time as well (we discuss these at the end). In the following steps, we walk through the process of manipulating and deriving example covariates. For the time invariant covariates, we will add them to our locs dataframe imported above. 7.1.1 Locally collected covariates You may have collected some data in the field when deploying or checking your camera traps, and kept that data separate from your camera trap data (e.g. vegetation assessments). Provided that the naming convention you gave to these dataframes is the same as in your camera data (e.g. the location is in a column called placename) - you can do a ’left_join()` to merge the two datasets. Import a sample set of local covariates and look at it: # Import local_covs &lt;- read.csv(&quot;data/raw_data/example_covariates/example_dataframe.csv&quot;) # Add it to you locations datafile locs &lt;- left_join(locs, local_covs) # From the dplyr package ## Joining with `by = join_by(placename)` # Look at the data local_covs %&gt;% kbl() %&gt;% kableExtra::scroll_box(height = &quot;250px&quot;) placename line_of_sight_m ALG001 137.12500 ALG002 131.52778 ALG003 353.65833 ALG004 158.04167 ALG005 305.81944 ALG006 60.12500 ALG007 310.58333 ALG008 112.75000 ALG009 299.02778 ALG010 102.30556 ALG011 223.56944 ALG012 140.91667 ALG013 394.56944 ALG014 196.87500 ALG015 163.11111 ALG016 116.11111 ALG017 138.19444 ALG018 304.29167 ALG019 330.97222 ALG020 204.40278 ALG021 264.94444 ALG022 229.13889 ALG023 218.29167 ALG024 425.43056 ALG025 56.97222 ALG026 200.05556 ALG027 252.95833 ALG028 277.50000 ALG029 206.52778 ALG030 43.38889 ALG031 334.27778 ALG032 83.00000 ALG033 165.00000 ALG034 337.79167 ALG035 439.61111 ALG036 62.69444 ALG037 392.61111 ALG038 352.75000 ALG039 339.76389 ALG040 182.75000 ALG041 109.25000 ALG042 219.56944 ALG043 62.41667 ALG044 374.26389 ALG045 294.83333 ALG046 34.50000 ALG047 363.80556 ALG048 392.93056 ALG049 80.77778 ALG050 139.36111 ALG051 208.12500 ALG052 13.95833 ALG053 99.30556 ALG054 35.47222 ALG055 189.06944 ALG056 55.41667 ALG057 93.04167 ALG058 80.91667 ALG059 41.00000 ALG060 189.90278 ALG061 11.16667 ALG062 16.00000 ALG063 28.94444 ALG064 34.27778 ALG065 20.11111 ALG066 36.94444 ALG067 188.83333 ALG068 72.27778 ALG069 22.85556 ALG070 28.61111 ALG071 20.05556 ALG072 52.44444 ALG073 55.94444 It is a dataframe where the survey locations are rows and the local covariates, in this case line_of_sight_m, are columns. We added this data to our station data using a left_join() operation from the dplyr() package. It uses a key variable which is common in both data frames to add data from the “right-hand side” to the rows in the “left-hand side” which are not already present. Any rows present in the right-hand side which are not in the left-hand side will be skipped. For more examples of joins using dplyr() see: https://dplyr.tidyverse.org/reference/mutate-joins.html 7.1.2 Remotely collected covariates To exploit remotely collected data sources we need to use the sf package to help us with spatial data. Lets convert our “normal” dataframe to an sf dataframe: # Convert locs_sf &lt;- st_as_sf(locs, # We specify the dataframe coords=c(&quot;longitude&quot;, &quot;latitude&quot;), # The XY coordinates crs=4326) # And the projection code # Look locs_sf ## Simple feature collection with 38 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -112.6467 ymin: 56.15983 xmax: -112.3848 ymax: 56.49352 ## Geodetic CRS: WGS 84 ## First 10 features: ## project_id placename feature_type line_of_sight_m ## 1 AlgarRestorationProject ALG027 HumanUse 252.95833 ## 2 AlgarRestorationProject ALG029 HumanUse 206.52778 ## 3 AlgarRestorationProject ALG031 HumanUse 334.27778 ## 4 AlgarRestorationProject ALG032 HumanUse 83.00000 ## 5 AlgarRestorationProject ALG035 HumanUse 439.61111 ## 6 AlgarRestorationProject ALG036 NatRegen 62.69444 ## 7 AlgarRestorationProject ALG037 HumanUse 392.61111 ## 8 AlgarRestorationProject ALG038 HumanUse 352.75000 ## 9 AlgarRestorationProject ALG039 HumanUse 339.76389 ## 10 AlgarRestorationProject ALG043 NatRegen 62.41667 ## geometry ## 1 POINT (-112.4735 56.3328) ## 2 POINT (-112.5483 56.39474) ## 3 POINT (-112.482 56.30899) ## 4 POINT (-112.3968 56.40197) ## 5 POINT (-112.4761 56.38428) ## 6 POINT (-112.4058 56.23178) ## 7 POINT (-112.4449 56.27898) ## 8 POINT (-112.4792 56.27039) ## 9 POINT (-112.4094 56.30127) ## 10 POINT (-112.5842 56.38715) That weird header is important - it tells you the type of data you have (lines, points, polygons etc), and the projection information (CRS). For more in depth information of sf functionality see: https://r-spatial.github.io/sf/articles/sf1.html 7.1.3 Extracting data from local rasters Often we have raster data layers stored which we would like to link to our camera locations. We have included one such example here, a raster which reflects the depth from the soil surface to the water table - a proxy for habitat type in this study site. The layer comes from the 1m Wet Area Mapping (WAM) layer: White, Barry, et al. “Using the cartographic depth-to-water index to locate small streams and associated wet areas across landscapes.” Canadian Water Resources Journal 37.4 (2012): 333-347. NOTE the raster has been down scaled to reduce its size for this course - it is no longer at 1m resolution. The only time we deviate from the sf package is to deal with rasters. Raster objects in R are processed really slowly, especially if the raster is large. So instead we use the terra package. library(terra) # Import the example raster using the stars package ras &lt;- rast(&quot;data/raw_data/example_covariates/example_raster.tif&quot;) # Covert your sf locations to the same projection as your raster then put it in terra `vect` format, locs_terra &lt;- locs_sf %&gt;% st_transform(crs=st_crs(ras)) %&gt;% # change the projection to match the raster vect() # Turn it into a terra object # Plot the result plot(ras) # The terra package makes nice raster plots with legends plot(locs_terra, add=T) # Add the survey locations as black dots Great! Now lets buffer our camera locations by 250 meters, and take the average depth to water for each location: # Buffer by 250m locs_terra &lt;- buffer(locs_terra,250) # Extract the values to a temporary object - tmp tmp &lt;- raster::extract(ras, locs_terra, fun=mean) # Make a new column in locs_sf called water_depth_m # They are ordered the same way so no need for a fancy join locs_sf$water_depth_m &lt;- tmp$Depth2WatAlgar # Check the distribution of our data boxplot(locs_sf$water_depth_m) Most locations are on the water table (lowland sites), others are above it (upload sites), and they have different vegetation characteristics in the field. 7.1.4 elevatr package Camera studies often occur over a range of elevations - and we can quickly extract these elevations using the elevatr package and an sf dataframe. The src option specifies the sources of the DEM data. We use aws Amazon Web Service Terrain Tiles - which are available globally. The z option specifies the resolution of the underlying DEM, the high the value, the more detailed it is. However, it will take longer to run so do not go crazy. library(elevatr) locs_sf &lt;- get_elev_point(locs_sf, src=&quot;aws&quot;, #Amazon Web Service Terrain Tiles - available globally z = 12) # z specifies the zoom level, the lower the value the faster the code runs, but the coarser the elevation values are # Plot the result boxplot(locs_sf$elevation) An elevation of ~ 500m was expected. Great! If you want to download a full elevation raster for your area of interests, see the introduction to elevatr 7.1.5 Open Street Maps Open Street Map (OSM) is an incredible resource for generating covariates for camera trap studies. For example, we might be interested in the distance to the nearest rivers, roads, or trails. All of these anthropogenic features are available in OSM! CAREFUL OSM data is user contributed and often incomplete and patchy. Always plot your data and never assume it is complete without checking it first. For an example fo this see water bodies below. First lets load the osmdata package. library(osmdata) The types of features we can extract using the osmdata package are listed here: https://wiki.openstreetmap.org/wiki/Map_features. 7.1.5.1 Highways Camera trap projects are often interested in human disturbance, of which, highways are an important part. Let’s start by defining our area of interest. All osmdata queries begin with a bounding box defining the area of the query: # First buffer our points by 10km to create an area of interest (aoi) aoi &lt;- st_bbox(st_buffer(locs_sf, 10000)) # Units are in meters # Return the features inside the bounding box highway &lt;- opq(aoi) %&gt;% #using the bounding box add_osm_feature(key=&quot;highway&quot;) %&gt;% #extract all highway features osmdata_sf() # convert them into simple features format The data you extract is its own “class” of data made up from multiple data types. The key thing is that it is made up of multiple data slices, each of which represents an sf dataset. Let’s take a look at three of these - $osm_points - $osm_lines - $osm_polygons Let’s use the lines element and add our camera stations, then calculate the distances to them: # Create an index of the nearest object in `highway$osm_lines` to locs_sf index &lt;- st_nearest_feature(locs_sf, highway$osm_lines) # Use that index to ask for the distance to that object locs_sf$road_dist_m &lt;- st_distance(locs_sf, highway$osm_lines[index,], by_element=T) # Note `by_element=T` tells st_distance to evaluate things line by line. # Plot the data par(mfrow=c(1,1)) plot(st_as_sfc(aoi)) # st_as_sfc created a polygon from a `bbox` object plot(st_geometry(highway$osm_lines), add=T) plot(st_geometry(locs_sf), col=&quot;red&quot;, add=T) st_nearest_feature gives us the index number of the feature which is closest to each station. We can the use this to request the distance from that nearest feature to each camera station using st_distance. Which, put together, looks like: 7.1.5.2 water bodies We also might want to calculate the distances to the nearest water body, and important resource for wildlife. We can do that using the following: water &lt;- opq(aoi) %&gt;% add_osm_feature(key=&quot;water&quot;) %&gt;% osmdata_sf() # This time we will use the points file index &lt;- st_nearest_feature(locs_sf, water$osm_points) locs_sf$water_dist_m &lt;- st_distance(locs_sf, water$osm_points[index,], by_element=T) # Note `by_element=T` tells st_distance to evaluate things line by line. For more examples of using the osmdata package see: the projects github page 7.1.6 Vegetation productivity 7.1.6.1 MODISTools MODIStools is an R interface to the MODIS Land Products Subsets web services. It allows for easy access to ‘MODIS’ time series directly to your computer! These are the data layers commonly used to extract normalized difference vegetation index (NDVI) and Enhanced Vegetation Index (EVI) information. When using MODIStools you should reference: Hufkens (2022). The MODISTools package: an interface to the MODIS Land Products Subsets Web Services Also click that link for more details on how to use it. Two commonly data products are MOD13Q1 for the derivation of NDVI/EVI, and MOD15A2H for the derivation of leaf area index (LAI). Let’s load the package and get it into the right format: library(MODISTools) # Select the location data and put it into the format MODIS tools expects modis_locs &lt;- locs %&gt;% select(&quot;placename&quot;, &quot;longitude&quot;, &quot;latitude&quot;) %&gt;% rename(site_name=placename, lat=latitude, lon=longitude) # Download some NDVI data site_ndvi &lt;- mt_batch_subset(product = &quot;MOD13Q1&quot;, df=modis_locs, band = &quot;250m_16_days_NDVI&quot;, start = &quot;2019-07-01&quot;, end = &quot;2019-08-31&quot;, km_lr = 0, # Use these options if you want to buffer the value (km left) km_ab = 0, # Use these options if you want to buffer the value (km above) internal = TRUE) Lets simplify the output to the key elements of information and rename them to match our camera data where appropriate: # Reduce the number of columsn in the output and rename it where required. ndvi_simple &lt;- site_ndvi %&gt;% select( site, band, calendar_date, value) %&gt;% rename(placename=site) # Take the average for each location tmp &lt;- ndvi_simple %&gt;% #Take the NDVI layer group_by(placename) %&gt;% # Group observations by the placename summarize(mean_ndvi=mean(value)) # Take the mean of the values and call the new column `mean_ndvi` # Add the new data to our locations dataframe locs_sf &lt;- left_join(locs_sf, tmp) # Plot the results boxplot(locs_sf$mean_ndvi, ylab=&quot;Mean NDVI score&quot;, las=1) It is possible to generate an NDVI score for each month that each camera is active, however that would take too long to produce for this course! 7.2 Convert and save your covariates # Convert columns to numeric locs_sf$road_dist_m &lt;- as.numeric(locs_sf$road_dist_m) # Convert it back to a dataframe locs_sf$geometry &lt;- NULL locs &lt;- left_join(locs, locs_sf) # Write the dataset write.csv(locs, paste0(&quot;data/processed_data/&quot;, locs$project_id[1],&quot;_camera_locations_and_covariates.csv&quot;), row.names=F) 7.3 Correlations between predictors So we have used a variety of different techniques to generate covariates for our subsequent analyses. However, it is important to note that we cannot just through these variables into a model. One way to check if your different variables are confound/correlated is using the corrplot package. library(corrplot) # First we need to create a correlation matrix between the different variables of interest M &lt;- cor(locs[, c(&quot;line_of_sight_m&quot;, &quot;water_depth_m&quot;, &quot;elevation&quot;, &quot;road_dist_m&quot;, &quot;mean_ndvi&quot;)]) corrplot(M, #The correlation matrix we made method=&quot;color&quot;, # How we want the cells type=&quot;upper&quot;, # Just show the upper part (it is usually mirrored) order=&quot;hclust&quot;, # Order the variables using the hclust method addCoef.col = &quot;black&quot;, # Add coefficient of correlation tl.col=&quot;black&quot;, tl.srt=45, # Control the text label color and rotation diag=F # Suppress the diagonal correlations (which are 1 anyway) ) The cells denote pairwise correlations between the rows and the columns. The great thing about corrplot is customization option are near endless - see the corrplot vignette. In general there is very low correlation between our different predictors! If we were seeing pairwise correlations &gt;0.7 we perhaps wouldn’t include those in the same model. "],["exploration.html", "Chapter 8 Analysis data exploration 8.1 Final locations plot 8.2 Independent detections summary 8.3 Temporal patterns in capture rates 8.4 Species-specific capture rates 8.5 Spatial patterns in capture rates 8.6 Species co-occurences 8.7 Covariate plots", " Chapter 8 Analysis data exploration Now things start to get really interesting - we are getting closer to analyzing our data. Before we get into building any models however, we must thoroughly explore our data. We want to ask questions like? How many species did we detect? Which are the most common? Where did we detect them? When did we detect them? How do species detections relate to our covariates? In the error checking section we focused our ‘data exploration’ on figures which would help us find issues with our data, now we want to shift gears and create plots which actually tell us about patterns in our data. To reflect the change from error check to patterns, all of the datasets we use will now be coming out of the data/processed_data/ folder. Create a new .R script Call it 03_example_exploration.R. Load the required packages # Check you have them and load them list.of.packages &lt;- c(&quot;kableExtra&quot;, &quot;tidyr&quot;, &quot;leaflet&quot;, &quot;dplyr&quot;, &quot;viridis&quot;, &quot;corrplot&quot;, &quot;lubridate&quot;, &quot;plotly&quot;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) lapply(list.of.packages, require, character.only = TRUE) 8.1 Final locations plot So lets read in the camera_locations.csv and plot the final survey locations in leaflet. We repeat this as we may have filtered out some stations in the error checking section - for example if they failed to collect any useful data: locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;) # If you want to color by a category do it here: category &lt;- &quot;feature_type&quot; # First lets choose a category to color locs[,category] &lt;- factor(locs[,category]) col.cat &lt;- turbo(length(levels(locs[,category]))) # Add it to the dataframe locs$colours &lt;- col.cat[locs[,category]] m &lt;- leaflet() %&gt;% # Add a satellite image layer addProviderTiles(providers$Esri.WorldImagery, group=&quot;Satellite&quot;) %&gt;% addProviderTiles(providers$Esri.WorldTopoMap, group=&quot;Base&quot;) %&gt;% addCircleMarkers(lng=locs$longitude, lat=locs$latitude, # Color the markers depending on the &#39;feature type&#39; color=locs$colours, # Add a popup of the deployment code popup=paste(locs$placename, locs[,category])) %&gt;% # Add a legend explaining what is going on addLegend(&quot;bottomleft&quot;, colors = col.cat, labels = levels(locs[,category]), title = category, labFormat = labelFormat(prefix = &quot;$&quot;), opacity = 1 ) %&gt;% # add a layer control box to toggle between the layers addLayersControl( baseGroups = c(&quot;Satellite&quot;, &quot;Base&quot;), options = layersControlOptions(collapsed = FALSE) ) m 8.2 Independent detections summary When you are writing papers or reports based on camera data, it is useful to have a capture summary table in the main text or as an appendix. We will use the species list we created to append summary information to: # Also read in the species list sp_summary &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_species_list.csv&quot;, header=T) # Import the ...total_observations.csv file total_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_total_observations.csv&quot;, header=T) The format of the output tables is what we would call ‘wide’ format - we have multiple species observation on the same row. placename days Alces.alces Canis.latrans Canis.lupus Cervus.canadensis Lepus.americanus Lontra.canadensis Lynx.canadensis Martes.americana Odocoileus.virginianus Oryctolagus.cuniculus Rangifer.tarandus Tamiasciurus.hudsonicus Ursus.americanus Vulpes.vulpes ALG027 358 4 4 13 1 0 0 10 0 3 0 0 0 32 0 ALG029 593 17 0 2 0 0 0 1 0 35 0 0 0 9 0 ALG031 593 11 0 8 0 1 1 0 6 1 1 21 0 2 1 ALG032 592 2 0 0 0 0 0 1 0 2 0 5 0 0 0 ALG035 594 11 0 2 0 7 0 1 0 1 0 6 3 2 0 ALG036 417 1 0 0 0 42 0 1 0 5 0 0 15 0 0 ALG037 592 2 0 0 0 0 0 0 0 0 0 3 0 2 0 ALG038 593 0 0 0 0 0 0 0 1 0 0 12 0 1 0 ALG039 591 2 0 6 0 0 0 0 0 0 0 5 0 3 0 ALG043 392 6 0 0 0 13 0 0 0 21 0 0 0 2 0 ALG044 392 15 0 3 0 2 0 0 1 10 0 0 0 7 2 ALG045 418 5 0 5 0 3 0 4 3 0 0 1 0 6 0 ALG046 592 9 0 0 0 14 0 1 0 18 0 0 0 0 1 ALG047 507 1 1 13 0 1 0 0 0 15 0 5 1 9 0 ALG048 593 0 0 2 0 0 0 1 1 1 0 7 0 4 0 ALG049 341 2 0 0 0 0 0 0 1 14 0 0 4 10 0 ALG052 590 13 0 3 0 9 0 1 1 65 0 1 0 17 0 ALG053 592 3 0 0 0 0 0 1 0 0 0 1 0 2 3 ALG054 595 1 0 1 0 25 0 3 0 28 0 0 0 2 0 ALG055 592 3 3 26 0 29 0 9 1 19 0 0 2 10 2 ALG056 595 8 0 0 0 0 0 1 0 6 0 0 0 2 0 ALG057 405 0 0 1 0 0 0 0 0 13 1 0 0 2 0 ALG058 595 2 0 0 0 58 0 3 0 51 0 1 0 11 0 ALG059 465 7 0 0 0 2 0 1 0 0 0 3 0 9 0 ALG060 592 1 0 0 0 1 0 1 2 0 0 0 0 6 0 ALG061 590 0 0 0 0 0 0 0 4 60 0 0 0 5 0 ALG062 592 1 0 4 0 4 0 1 0 48 0 0 0 16 0 ALG063 593 1 0 1 0 1 0 0 1 23 0 4 1 2 0 ALG064 592 2 0 0 0 0 0 0 0 0 0 10 0 0 0 ALG065 447 26 0 0 0 0 0 0 1 0 0 1 0 2 0 ALG066 591 2 0 0 0 0 0 1 0 1 0 6 0 0 0 ALG067 391 2 0 2 0 0 0 0 0 3 0 0 0 0 0 ALG068 592 3 0 0 0 0 0 0 0 0 0 0 0 2 0 ALG069 592 6 0 0 0 3 0 4 0 64 0 0 0 25 0 ALG070 408 2 0 0 0 0 0 0 1 4 0 3 0 1 0 ALG071 595 3 0 1 0 21 0 2 0 46 0 0 0 22 1 ALG072 595 1 0 0 0 5 0 4 0 5 0 1 0 3 0 ALG073 593 1 0 0 0 0 0 0 0 0 0 23 0 0 0 Sometimes, however, we might want a “longer” format where every row represents a unique species_site combination. We can do this using the ‘pivot_longer’ function: long_obs &lt;- total_obs %&gt;% pivot_longer(cols=sp_summary$sp, # The columns we want to create into rows - species names_to=&quot;sp&quot;, # What we what the number column to be called values_to = &quot;count&quot;) # Takes the values in the species columns and calls them `count` We now have a dataframe where each row is a unique species at a given location (e.g. ALG027) - a.k.a. long format! placename days sp count ALG027 358 Alces.alces 4 ALG027 358 Cervus.canadensis 1 ALG027 358 Odocoileus.virginianus 3 ALG027 358 Rangifer.tarandus 0 ALG027 358 Canis.latrans 4 ALG027 358 Canis.lupus 13 ALG027 358 Vulpes.vulpes 0 ALG027 358 Lynx.canadensis 10 ALG027 358 Lontra.canadensis 0 ALG027 358 Martes.americana 0 ALG027 358 Ursus.americanus 32 ALG027 358 Lepus.americanus 0 ALG027 358 Oryctolagus.cuniculus 0 ALG027 358 Tamiasciurus.hudsonicus 0 ALG029 593 Alces.alces 17 ALG029 593 Cervus.canadensis 0 ALG029 593 Odocoileus.virginianus 35 ALG029 593 Rangifer.tarandus 0 ALG029 593 Canis.latrans 0 ALG029 593 Canis.lupus 2 ALG029 593 Vulpes.vulpes 0 ALG029 593 Lynx.canadensis 1 ALG029 593 Lontra.canadensis 0 ALG029 593 Martes.americana 0 ALG029 593 Ursus.americanus 9 ALG029 593 Lepus.americanus 0 ALG029 593 Oryctolagus.cuniculus 0 ALG029 593 Tamiasciurus.hudsonicus 0 ALG031 593 Alces.alces 11 ALG031 593 Cervus.canadensis 0 ALG031 593 Odocoileus.virginianus 1 ALG031 593 Rangifer.tarandus 21 ALG031 593 Canis.latrans 0 ALG031 593 Canis.lupus 8 ALG031 593 Vulpes.vulpes 1 ALG031 593 Lynx.canadensis 0 ALG031 593 Lontra.canadensis 1 ALG031 593 Martes.americana 6 ALG031 593 Ursus.americanus 2 ALG031 593 Lepus.americanus 1 ALG031 593 Oryctolagus.cuniculus 1 ALG031 593 Tamiasciurus.hudsonicus 0 ALG032 592 Alces.alces 2 ALG032 592 Cervus.canadensis 0 ALG032 592 Odocoileus.virginianus 2 ALG032 592 Rangifer.tarandus 5 ALG032 592 Canis.latrans 0 ALG032 592 Canis.lupus 0 ALG032 592 Vulpes.vulpes 0 ALG032 592 Lynx.canadensis 1 ALG032 592 Lontra.canadensis 0 ALG032 592 Martes.americana 0 ALG032 592 Ursus.americanus 0 ALG032 592 Lepus.americanus 0 ALG032 592 Oryctolagus.cuniculus 0 ALG032 592 Tamiasciurus.hudsonicus 0 ALG035 594 Alces.alces 11 ALG035 594 Cervus.canadensis 0 ALG035 594 Odocoileus.virginianus 1 ALG035 594 Rangifer.tarandus 6 ALG035 594 Canis.latrans 0 ALG035 594 Canis.lupus 2 ALG035 594 Vulpes.vulpes 0 ALG035 594 Lynx.canadensis 1 ALG035 594 Lontra.canadensis 0 ALG035 594 Martes.americana 0 ALG035 594 Ursus.americanus 2 ALG035 594 Lepus.americanus 7 ALG035 594 Oryctolagus.cuniculus 0 ALG035 594 Tamiasciurus.hudsonicus 3 ALG036 417 Alces.alces 1 ALG036 417 Cervus.canadensis 0 ALG036 417 Odocoileus.virginianus 5 ALG036 417 Rangifer.tarandus 0 ALG036 417 Canis.latrans 0 ALG036 417 Canis.lupus 0 ALG036 417 Vulpes.vulpes 0 ALG036 417 Lynx.canadensis 1 ALG036 417 Lontra.canadensis 0 ALG036 417 Martes.americana 0 ALG036 417 Ursus.americanus 0 ALG036 417 Lepus.americanus 42 ALG036 417 Oryctolagus.cuniculus 0 ALG036 417 Tamiasciurus.hudsonicus 15 ALG037 592 Alces.alces 2 ALG037 592 Cervus.canadensis 0 ALG037 592 Odocoileus.virginianus 0 ALG037 592 Rangifer.tarandus 3 ALG037 592 Canis.latrans 0 ALG037 592 Canis.lupus 0 ALG037 592 Vulpes.vulpes 0 ALG037 592 Lynx.canadensis 0 ALG037 592 Lontra.canadensis 0 ALG037 592 Martes.americana 0 ALG037 592 Ursus.americanus 2 ALG037 592 Lepus.americanus 0 ALG037 592 Oryctolagus.cuniculus 0 ALG037 592 Tamiasciurus.hudsonicus 0 ALG038 593 Alces.alces 0 ALG038 593 Cervus.canadensis 0 ALG038 593 Odocoileus.virginianus 0 ALG038 593 Rangifer.tarandus 12 ALG038 593 Canis.latrans 0 ALG038 593 Canis.lupus 0 ALG038 593 Vulpes.vulpes 0 ALG038 593 Lynx.canadensis 0 ALG038 593 Lontra.canadensis 0 ALG038 593 Martes.americana 1 ALG038 593 Ursus.americanus 1 ALG038 593 Lepus.americanus 0 ALG038 593 Oryctolagus.cuniculus 0 ALG038 593 Tamiasciurus.hudsonicus 0 ALG039 591 Alces.alces 2 ALG039 591 Cervus.canadensis 0 ALG039 591 Odocoileus.virginianus 0 ALG039 591 Rangifer.tarandus 5 ALG039 591 Canis.latrans 0 ALG039 591 Canis.lupus 6 ALG039 591 Vulpes.vulpes 0 ALG039 591 Lynx.canadensis 0 ALG039 591 Lontra.canadensis 0 ALG039 591 Martes.americana 0 ALG039 591 Ursus.americanus 3 ALG039 591 Lepus.americanus 0 ALG039 591 Oryctolagus.cuniculus 0 ALG039 591 Tamiasciurus.hudsonicus 0 ALG043 392 Alces.alces 6 ALG043 392 Cervus.canadensis 0 ALG043 392 Odocoileus.virginianus 21 ALG043 392 Rangifer.tarandus 0 ALG043 392 Canis.latrans 0 ALG043 392 Canis.lupus 0 ALG043 392 Vulpes.vulpes 0 ALG043 392 Lynx.canadensis 0 ALG043 392 Lontra.canadensis 0 ALG043 392 Martes.americana 0 ALG043 392 Ursus.americanus 2 ALG043 392 Lepus.americanus 13 ALG043 392 Oryctolagus.cuniculus 0 ALG043 392 Tamiasciurus.hudsonicus 0 ALG044 392 Alces.alces 15 ALG044 392 Cervus.canadensis 0 ALG044 392 Odocoileus.virginianus 10 ALG044 392 Rangifer.tarandus 0 ALG044 392 Canis.latrans 0 ALG044 392 Canis.lupus 3 ALG044 392 Vulpes.vulpes 2 ALG044 392 Lynx.canadensis 0 ALG044 392 Lontra.canadensis 0 ALG044 392 Martes.americana 1 ALG044 392 Ursus.americanus 7 ALG044 392 Lepus.americanus 2 ALG044 392 Oryctolagus.cuniculus 0 ALG044 392 Tamiasciurus.hudsonicus 0 ALG045 418 Alces.alces 5 ALG045 418 Cervus.canadensis 0 ALG045 418 Odocoileus.virginianus 0 ALG045 418 Rangifer.tarandus 1 ALG045 418 Canis.latrans 0 ALG045 418 Canis.lupus 5 ALG045 418 Vulpes.vulpes 0 ALG045 418 Lynx.canadensis 4 ALG045 418 Lontra.canadensis 0 ALG045 418 Martes.americana 3 ALG045 418 Ursus.americanus 6 ALG045 418 Lepus.americanus 3 ALG045 418 Oryctolagus.cuniculus 0 ALG045 418 Tamiasciurus.hudsonicus 0 ALG046 592 Alces.alces 9 ALG046 592 Cervus.canadensis 0 ALG046 592 Odocoileus.virginianus 18 ALG046 592 Rangifer.tarandus 0 ALG046 592 Canis.latrans 0 ALG046 592 Canis.lupus 0 ALG046 592 Vulpes.vulpes 1 ALG046 592 Lynx.canadensis 1 ALG046 592 Lontra.canadensis 0 ALG046 592 Martes.americana 0 ALG046 592 Ursus.americanus 0 ALG046 592 Lepus.americanus 14 ALG046 592 Oryctolagus.cuniculus 0 ALG046 592 Tamiasciurus.hudsonicus 0 ALG047 507 Alces.alces 1 ALG047 507 Cervus.canadensis 0 ALG047 507 Odocoileus.virginianus 15 ALG047 507 Rangifer.tarandus 5 ALG047 507 Canis.latrans 1 ALG047 507 Canis.lupus 13 ALG047 507 Vulpes.vulpes 0 ALG047 507 Lynx.canadensis 0 ALG047 507 Lontra.canadensis 0 ALG047 507 Martes.americana 0 ALG047 507 Ursus.americanus 9 ALG047 507 Lepus.americanus 1 ALG047 507 Oryctolagus.cuniculus 0 ALG047 507 Tamiasciurus.hudsonicus 1 ALG048 593 Alces.alces 0 ALG048 593 Cervus.canadensis 0 ALG048 593 Odocoileus.virginianus 1 ALG048 593 Rangifer.tarandus 7 ALG048 593 Canis.latrans 0 ALG048 593 Canis.lupus 2 ALG048 593 Vulpes.vulpes 0 ALG048 593 Lynx.canadensis 1 ALG048 593 Lontra.canadensis 0 ALG048 593 Martes.americana 1 ALG048 593 Ursus.americanus 4 ALG048 593 Lepus.americanus 0 ALG048 593 Oryctolagus.cuniculus 0 ALG048 593 Tamiasciurus.hudsonicus 0 ALG049 341 Alces.alces 2 ALG049 341 Cervus.canadensis 0 ALG049 341 Odocoileus.virginianus 14 ALG049 341 Rangifer.tarandus 0 ALG049 341 Canis.latrans 0 ALG049 341 Canis.lupus 0 ALG049 341 Vulpes.vulpes 0 ALG049 341 Lynx.canadensis 0 ALG049 341 Lontra.canadensis 0 ALG049 341 Martes.americana 1 ALG049 341 Ursus.americanus 10 ALG049 341 Lepus.americanus 0 ALG049 341 Oryctolagus.cuniculus 0 ALG049 341 Tamiasciurus.hudsonicus 4 ALG052 590 Alces.alces 13 ALG052 590 Cervus.canadensis 0 ALG052 590 Odocoileus.virginianus 65 ALG052 590 Rangifer.tarandus 1 ALG052 590 Canis.latrans 0 ALG052 590 Canis.lupus 3 ALG052 590 Vulpes.vulpes 0 ALG052 590 Lynx.canadensis 1 ALG052 590 Lontra.canadensis 0 ALG052 590 Martes.americana 1 ALG052 590 Ursus.americanus 17 ALG052 590 Lepus.americanus 9 ALG052 590 Oryctolagus.cuniculus 0 ALG052 590 Tamiasciurus.hudsonicus 0 ALG053 592 Alces.alces 3 ALG053 592 Cervus.canadensis 0 ALG053 592 Odocoileus.virginianus 0 ALG053 592 Rangifer.tarandus 1 ALG053 592 Canis.latrans 0 ALG053 592 Canis.lupus 0 ALG053 592 Vulpes.vulpes 3 ALG053 592 Lynx.canadensis 1 ALG053 592 Lontra.canadensis 0 ALG053 592 Martes.americana 0 ALG053 592 Ursus.americanus 2 ALG053 592 Lepus.americanus 0 ALG053 592 Oryctolagus.cuniculus 0 ALG053 592 Tamiasciurus.hudsonicus 0 ALG054 595 Alces.alces 1 ALG054 595 Cervus.canadensis 0 ALG054 595 Odocoileus.virginianus 28 ALG054 595 Rangifer.tarandus 0 ALG054 595 Canis.latrans 0 ALG054 595 Canis.lupus 1 ALG054 595 Vulpes.vulpes 0 ALG054 595 Lynx.canadensis 3 ALG054 595 Lontra.canadensis 0 ALG054 595 Martes.americana 0 ALG054 595 Ursus.americanus 2 ALG054 595 Lepus.americanus 25 ALG054 595 Oryctolagus.cuniculus 0 ALG054 595 Tamiasciurus.hudsonicus 0 ALG055 592 Alces.alces 3 ALG055 592 Cervus.canadensis 0 ALG055 592 Odocoileus.virginianus 19 ALG055 592 Rangifer.tarandus 0 ALG055 592 Canis.latrans 3 ALG055 592 Canis.lupus 26 ALG055 592 Vulpes.vulpes 2 ALG055 592 Lynx.canadensis 9 ALG055 592 Lontra.canadensis 0 ALG055 592 Martes.americana 1 ALG055 592 Ursus.americanus 10 ALG055 592 Lepus.americanus 29 ALG055 592 Oryctolagus.cuniculus 0 ALG055 592 Tamiasciurus.hudsonicus 2 ALG056 595 Alces.alces 8 ALG056 595 Cervus.canadensis 0 ALG056 595 Odocoileus.virginianus 6 ALG056 595 Rangifer.tarandus 0 ALG056 595 Canis.latrans 0 ALG056 595 Canis.lupus 0 ALG056 595 Vulpes.vulpes 0 ALG056 595 Lynx.canadensis 1 ALG056 595 Lontra.canadensis 0 ALG056 595 Martes.americana 0 ALG056 595 Ursus.americanus 2 ALG056 595 Lepus.americanus 0 ALG056 595 Oryctolagus.cuniculus 0 ALG056 595 Tamiasciurus.hudsonicus 0 ALG057 405 Alces.alces 0 ALG057 405 Cervus.canadensis 0 ALG057 405 Odocoileus.virginianus 13 ALG057 405 Rangifer.tarandus 0 ALG057 405 Canis.latrans 0 ALG057 405 Canis.lupus 1 ALG057 405 Vulpes.vulpes 0 ALG057 405 Lynx.canadensis 0 ALG057 405 Lontra.canadensis 0 ALG057 405 Martes.americana 0 ALG057 405 Ursus.americanus 2 ALG057 405 Lepus.americanus 0 ALG057 405 Oryctolagus.cuniculus 1 ALG057 405 Tamiasciurus.hudsonicus 0 ALG058 595 Alces.alces 2 ALG058 595 Cervus.canadensis 0 ALG058 595 Odocoileus.virginianus 51 ALG058 595 Rangifer.tarandus 1 ALG058 595 Canis.latrans 0 ALG058 595 Canis.lupus 0 ALG058 595 Vulpes.vulpes 0 ALG058 595 Lynx.canadensis 3 ALG058 595 Lontra.canadensis 0 ALG058 595 Martes.americana 0 ALG058 595 Ursus.americanus 11 ALG058 595 Lepus.americanus 58 ALG058 595 Oryctolagus.cuniculus 0 ALG058 595 Tamiasciurus.hudsonicus 0 ALG059 465 Alces.alces 7 ALG059 465 Cervus.canadensis 0 ALG059 465 Odocoileus.virginianus 0 ALG059 465 Rangifer.tarandus 3 ALG059 465 Canis.latrans 0 ALG059 465 Canis.lupus 0 ALG059 465 Vulpes.vulpes 0 ALG059 465 Lynx.canadensis 1 ALG059 465 Lontra.canadensis 0 ALG059 465 Martes.americana 0 ALG059 465 Ursus.americanus 9 ALG059 465 Lepus.americanus 2 ALG059 465 Oryctolagus.cuniculus 0 ALG059 465 Tamiasciurus.hudsonicus 0 ALG060 592 Alces.alces 1 ALG060 592 Cervus.canadensis 0 ALG060 592 Odocoileus.virginianus 0 ALG060 592 Rangifer.tarandus 0 ALG060 592 Canis.latrans 0 ALG060 592 Canis.lupus 0 ALG060 592 Vulpes.vulpes 0 ALG060 592 Lynx.canadensis 1 ALG060 592 Lontra.canadensis 0 ALG060 592 Martes.americana 2 ALG060 592 Ursus.americanus 6 ALG060 592 Lepus.americanus 1 ALG060 592 Oryctolagus.cuniculus 0 ALG060 592 Tamiasciurus.hudsonicus 0 ALG061 590 Alces.alces 0 ALG061 590 Cervus.canadensis 0 ALG061 590 Odocoileus.virginianus 60 ALG061 590 Rangifer.tarandus 0 ALG061 590 Canis.latrans 0 ALG061 590 Canis.lupus 0 ALG061 590 Vulpes.vulpes 0 ALG061 590 Lynx.canadensis 0 ALG061 590 Lontra.canadensis 0 ALG061 590 Martes.americana 4 ALG061 590 Ursus.americanus 5 ALG061 590 Lepus.americanus 0 ALG061 590 Oryctolagus.cuniculus 0 ALG061 590 Tamiasciurus.hudsonicus 0 ALG062 592 Alces.alces 1 ALG062 592 Cervus.canadensis 0 ALG062 592 Odocoileus.virginianus 48 ALG062 592 Rangifer.tarandus 0 ALG062 592 Canis.latrans 0 ALG062 592 Canis.lupus 4 ALG062 592 Vulpes.vulpes 0 ALG062 592 Lynx.canadensis 1 ALG062 592 Lontra.canadensis 0 ALG062 592 Martes.americana 0 ALG062 592 Ursus.americanus 16 ALG062 592 Lepus.americanus 4 ALG062 592 Oryctolagus.cuniculus 0 ALG062 592 Tamiasciurus.hudsonicus 0 ALG063 593 Alces.alces 1 ALG063 593 Cervus.canadensis 0 ALG063 593 Odocoileus.virginianus 23 ALG063 593 Rangifer.tarandus 4 ALG063 593 Canis.latrans 0 ALG063 593 Canis.lupus 1 ALG063 593 Vulpes.vulpes 0 ALG063 593 Lynx.canadensis 0 ALG063 593 Lontra.canadensis 0 ALG063 593 Martes.americana 1 ALG063 593 Ursus.americanus 2 ALG063 593 Lepus.americanus 1 ALG063 593 Oryctolagus.cuniculus 0 ALG063 593 Tamiasciurus.hudsonicus 1 ALG064 592 Alces.alces 2 ALG064 592 Cervus.canadensis 0 ALG064 592 Odocoileus.virginianus 0 ALG064 592 Rangifer.tarandus 10 ALG064 592 Canis.latrans 0 ALG064 592 Canis.lupus 0 ALG064 592 Vulpes.vulpes 0 ALG064 592 Lynx.canadensis 0 ALG064 592 Lontra.canadensis 0 ALG064 592 Martes.americana 0 ALG064 592 Ursus.americanus 0 ALG064 592 Lepus.americanus 0 ALG064 592 Oryctolagus.cuniculus 0 ALG064 592 Tamiasciurus.hudsonicus 0 ALG065 447 Alces.alces 26 ALG065 447 Cervus.canadensis 0 ALG065 447 Odocoileus.virginianus 0 ALG065 447 Rangifer.tarandus 1 ALG065 447 Canis.latrans 0 ALG065 447 Canis.lupus 0 ALG065 447 Vulpes.vulpes 0 ALG065 447 Lynx.canadensis 0 ALG065 447 Lontra.canadensis 0 ALG065 447 Martes.americana 1 ALG065 447 Ursus.americanus 2 ALG065 447 Lepus.americanus 0 ALG065 447 Oryctolagus.cuniculus 0 ALG065 447 Tamiasciurus.hudsonicus 0 ALG066 591 Alces.alces 2 ALG066 591 Cervus.canadensis 0 ALG066 591 Odocoileus.virginianus 1 ALG066 591 Rangifer.tarandus 6 ALG066 591 Canis.latrans 0 ALG066 591 Canis.lupus 0 ALG066 591 Vulpes.vulpes 0 ALG066 591 Lynx.canadensis 1 ALG066 591 Lontra.canadensis 0 ALG066 591 Martes.americana 0 ALG066 591 Ursus.americanus 0 ALG066 591 Lepus.americanus 0 ALG066 591 Oryctolagus.cuniculus 0 ALG066 591 Tamiasciurus.hudsonicus 0 ALG067 391 Alces.alces 2 ALG067 391 Cervus.canadensis 0 ALG067 391 Odocoileus.virginianus 3 ALG067 391 Rangifer.tarandus 0 ALG067 391 Canis.latrans 0 ALG067 391 Canis.lupus 2 ALG067 391 Vulpes.vulpes 0 ALG067 391 Lynx.canadensis 0 ALG067 391 Lontra.canadensis 0 ALG067 391 Martes.americana 0 ALG067 391 Ursus.americanus 0 ALG067 391 Lepus.americanus 0 ALG067 391 Oryctolagus.cuniculus 0 ALG067 391 Tamiasciurus.hudsonicus 0 ALG068 592 Alces.alces 3 ALG068 592 Cervus.canadensis 0 ALG068 592 Odocoileus.virginianus 0 ALG068 592 Rangifer.tarandus 0 ALG068 592 Canis.latrans 0 ALG068 592 Canis.lupus 0 ALG068 592 Vulpes.vulpes 0 ALG068 592 Lynx.canadensis 0 ALG068 592 Lontra.canadensis 0 ALG068 592 Martes.americana 0 ALG068 592 Ursus.americanus 2 ALG068 592 Lepus.americanus 0 ALG068 592 Oryctolagus.cuniculus 0 ALG068 592 Tamiasciurus.hudsonicus 0 ALG069 592 Alces.alces 6 ALG069 592 Cervus.canadensis 0 ALG069 592 Odocoileus.virginianus 64 ALG069 592 Rangifer.tarandus 0 ALG069 592 Canis.latrans 0 ALG069 592 Canis.lupus 0 ALG069 592 Vulpes.vulpes 0 ALG069 592 Lynx.canadensis 4 ALG069 592 Lontra.canadensis 0 ALG069 592 Martes.americana 0 ALG069 592 Ursus.americanus 25 ALG069 592 Lepus.americanus 3 ALG069 592 Oryctolagus.cuniculus 0 ALG069 592 Tamiasciurus.hudsonicus 0 ALG070 408 Alces.alces 2 ALG070 408 Cervus.canadensis 0 ALG070 408 Odocoileus.virginianus 4 ALG070 408 Rangifer.tarandus 3 ALG070 408 Canis.latrans 0 ALG070 408 Canis.lupus 0 ALG070 408 Vulpes.vulpes 0 ALG070 408 Lynx.canadensis 0 ALG070 408 Lontra.canadensis 0 ALG070 408 Martes.americana 1 ALG070 408 Ursus.americanus 1 ALG070 408 Lepus.americanus 0 ALG070 408 Oryctolagus.cuniculus 0 ALG070 408 Tamiasciurus.hudsonicus 0 ALG071 595 Alces.alces 3 ALG071 595 Cervus.canadensis 0 ALG071 595 Odocoileus.virginianus 46 ALG071 595 Rangifer.tarandus 0 ALG071 595 Canis.latrans 0 ALG071 595 Canis.lupus 1 ALG071 595 Vulpes.vulpes 1 ALG071 595 Lynx.canadensis 2 ALG071 595 Lontra.canadensis 0 ALG071 595 Martes.americana 0 ALG071 595 Ursus.americanus 22 ALG071 595 Lepus.americanus 21 ALG071 595 Oryctolagus.cuniculus 0 ALG071 595 Tamiasciurus.hudsonicus 0 ALG072 595 Alces.alces 1 ALG072 595 Cervus.canadensis 0 ALG072 595 Odocoileus.virginianus 5 ALG072 595 Rangifer.tarandus 1 ALG072 595 Canis.latrans 0 ALG072 595 Canis.lupus 0 ALG072 595 Vulpes.vulpes 0 ALG072 595 Lynx.canadensis 4 ALG072 595 Lontra.canadensis 0 ALG072 595 Martes.americana 0 ALG072 595 Ursus.americanus 3 ALG072 595 Lepus.americanus 5 ALG072 595 Oryctolagus.cuniculus 0 ALG072 595 Tamiasciurus.hudsonicus 0 ALG073 593 Alces.alces 1 ALG073 593 Cervus.canadensis 0 ALG073 593 Odocoileus.virginianus 0 ALG073 593 Rangifer.tarandus 23 ALG073 593 Canis.latrans 0 ALG073 593 Canis.lupus 0 ALG073 593 Vulpes.vulpes 0 ALG073 593 Lynx.canadensis 0 ALG073 593 Lontra.canadensis 0 ALG073 593 Martes.americana 0 ALG073 593 Ursus.americanus 0 ALG073 593 Lepus.americanus 0 ALG073 593 Oryctolagus.cuniculus 0 ALG073 593 Tamiasciurus.hudsonicus 0 It is often easier to use this long format to make summaries: # We can them summaries those using dplyr tmp &lt;- long_obs %&gt;% # Take the long observation data frame `long_obs` group_by(sp) %&gt;% # Group by species summarise(count=sum(count)) # Sum all the independent observations # Add it to the sp_summary dataframe sp_summary &lt;- left_join(sp_summary, tmp) 8.2.1 Raw occupancy We can very quickly flip a count to a presence/absence using as.logical this converts all integers to 1 and keeps 0’s as 0! # We use the mutate function to mutate the column total_binary &lt;- total_obs %&gt;% # The total obs dataframe mutate(across(sp_summary$sp, ~+as.logical(.x))) # across all of the species columns, make it binary # Flip the dataframe to longer - as before long_bin &lt;- total_binary %&gt;% pivot_longer(cols=sp_summary$sp, names_to=&quot;sp&quot;, values_to = &quot;count&quot;) # Takes the species names columns, and makes them unique rows with &quot;sp&quot; as the key # We can now sum the presence/absences and divide by the number of survey locations tmp &lt;- long_bin %&gt;% group_by(sp) %&gt;% summarise(occupancy=sum(count)/nrow(locs)) # divided the sum by the number of sites # add the results to the sp_summary sp_summary &lt;- left_join(sp_summary, tmp) ## Joining with `by = join_by(sp)` 8.2.2 Comparison plot Then we can use the dataframe created above to summaries the detections and the occupancy patterns. Note - here we weave two plotly graphs together using the subplot() function! # Lets put the dataframes in a sensible order sp_summary &lt;- sp_summary[order(sp_summary$count),] yform &lt;- list(categoryorder = &quot;array&quot;, categoryarray = sp_summary$sp) xform &lt;- list(title=&quot;Captures&quot;) # Capture rate fig1 &lt;- plot_ly(x = sp_summary$count, y = sp_summary$sp, type = &#39;bar&#39;, orientation = &#39;h&#39;) %&gt;% layout(yaxis = yform, xaxis=xform) yform &lt;- list(categoryorder = &quot;array&quot;, categoryarray = sp_summary$sp, showticklabels=F) xform &lt;- list(title=&quot;Occupancy&quot;) # Occupancy fig2 &lt;- plot_ly(x = sp_summary$occupancy, y = sp_summary$sp, type = &#39;bar&#39;, orientation = &#39;h&#39;) %&gt;% layout(yaxis = yform, xaxis=xform) subplot(nrows=1,fig1, fig2, titleX = T) # We could stack them on top of one another using nrows=2 What does this output tell you about species-specific occurrences across the landscape? 8.3 Temporal patterns in capture rates Next lets summaries the temporal patterns in the number of sites (placenames) surveyed, and the total number of animals captured. We will use the monthly dataframes in order to do this, but you could do it at the weekly or daily scale if required! We will first count the number of survey nights each location was active, then in the second step add the number of species detections. # Use the monthly observations dataset mon_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_monthly_observations.csv&quot;, header=T) # Count up the number of stations and the number of camera nights mon_summary &lt;- mon_obs %&gt;% # Use the monthly observations dataframe group_by(date) %&gt;% # Group by the date summarise(locs_active=n(), # Count the number of active cameras cam_days=sum(days)) # And sum the active days # Add in the species specific counts - and join it with the mon_summary dataframe mon_summary &lt;- mon_obs %&gt;% group_by(date) %&gt;% summarise(across(sp_summary$sp, sum, na.rm=TRUE)) %&gt;% # summarise across all of # the species columns left_join(x=mon_summary) # Join with the mon_summary dataframe Now lets use lubridate to convert the timestamp column to a date object and plot the output. Each black dot represents the number of survey nights or average capture rate, respectively. # We first need to convert the date column to a date object mon_summary$date &lt;- ym(mon_summary$date) # Set up a two panel plot (side by side) par(mfrow=c(1,2)) plot(mon_summary$date, mon_summary$locs_active, type=&quot;o&quot;, pch=19, ylim=c(0, max(mon_summary$locs_active)), las=1, ylab=&quot;Number of cameras active&quot;, xlab=&quot;Date&quot;) # Sum all the captures rates for the species columns mon_summary$all.sp &lt;- rowSums(mon_summary[, sp_summary$sp]) # Plot them plot(mon_summary$date, mon_summary$all.sp/(mon_summary$cam_days/100), type=&quot;o&quot;, pch=19, las=1, ylab=&quot;Detections per 100 cam days&quot;, xlab=&quot;Date&quot;) As we saw in the error checking section, survey effort (number of cameras active) drops in early 2018 (left hand panel). The right hand panel shows the overall capture rate (for all species pooled), and you can see it is strongly seasonal - peaks in summers, and drops in the winter. 8.4 Species-specific capture rates We should now split up this overall capture rate, and explore temporal patterns in species-specific detections. We can do this by looping the code with a for() loop. par(mfrow=c(2,2)) i &lt;- 1 for(i in 1:length(sp_summary$sp)) { plot(mon_summary$date, pull(mon_summary, sp_summary$sp[i])/(mon_summary$cam_days/100), # The pull command allows you to grab a specific column in a dataframe and turn it into a vector! type=&quot;o&quot;, pch=19, las=1, ylab=&quot;Detections per 100 cam days&quot;, xlab=&quot;Date&quot;, main=sp_summary$sp[i]) } Can you see any interesting patterns in here? What do black bears do in winter? What time of year do we get the most marten detections? 8.5 Spatial patterns in capture rates We also often want to explore if there are any spatial patterns in capture rates, these can hint at any ecological relationships we might want to explore further. Here we do it for just a single species, the white-tailed deer (Odocoileus virginianus). Here we make use of the ‘total_obs’ data frame we imported earlier. We also use the ‘locs’ dataframe. total_obs &lt;- left_join(total_obs, locs) focal_species &lt;- &quot;Odocoileus.virginianus&quot; focal_cr &lt;- pull(total_obs, focal_species)/(total_obs$days/100) m &lt;- leaflet() %&gt;% addProviderTiles(providers$Esri.WorldTopoMap, group=&quot;Base&quot;) %&gt;% addCircleMarkers(lng=locs$longitude, lat=locs$latitude, # Add a popup of the deployment code popup=paste(locs$placename), radius=(focal_cr/max(focal_cr)*10)+1, stroke=F, fillOpacity=0.6) m Try it for some different species. Can you see any different patterns? 8.6 Species co-occurences Camera trap data are being increasingly used to model multiple species communities. In the same way in which we used the corrplot package in the (analysis covariates section(#covariates), we can use it to explore the co-occurrence patterns of the species in the community. The plot below uses the ‘total_obs’ dataframe, and performs pairwise correlations between the species on the left, and the species on the top row. Blue colors = positive correlation -&gt; at locations where you have high counts of one species, you also have high counts of the paired species. Red colors = negative correlation -&gt; at locations where you have high counts of one species, then you are likely to have low counts of the species pair (or vice-versa). We implement a more nuanced form of this data analysis in the interactions chapter. To make this plot we use the total_obs dataframe. # Reset the plot parameters par(mfrow=c(1,1)) # Pull the data for each of the species from tmp &lt;- total_obs[, sp_summary$sp] M &lt;- cor(tmp) corrplot(M, method=&quot;color&quot;, type=&quot;upper&quot;, order=&quot;hclust&quot;, # addCoef.col = &quot;black&quot;, # We suppress the coefs to make a cleaner plot tl.col=&quot;black&quot;, tl.srt=45, #Text label color and rotation diag=FALSE ) What would you conclude? 8.7 Covariate plots So far we have explored temporal and spatial patterns in species counts - but what about the effects of the covariates we derived in the analysis covariates section? Before embarking on an in depth analysis, it is always sensible to plot your response terms against predictors. Note we are often paranoid about “data dredging” or shopping around for “significant” predictors, as this isn’t good scientific practice. Here, we should only explore covariates for which we have a prior belief in there effects on the response term. We are not looking for significant relationships, rather trying to understand the structure of our data! You should know your data inside out before you start modelling. Final note just because you do not see a strong effect in your raw data, doesn’t mean that it will not have an effect in your final models, particularly if you plan to account for multiple confounding variables or use random effects! We have - feature type, water_depth_m, line_of_sight_m, elevation, road_dist_m, water_dist_m, lcc_habitats and mean_ndvi as potential covariates. Before we proceed, it is good practice to convert categorical variables (like feature_type and lcc_habitats) to factors. There is a very easy way to do that using the mutate_if() function of dplyr: locs &lt;- locs %&gt;% mutate_if(is.character,as.factor) # If a column is a character string, make it a factor # Add the location variables to the dataframes total_obs &lt;- left_join(total_obs, locs) ## Joining with `by = join_by(placename, ## project_id, longitude, latitude, ## feature_type, line_of_sight_m, ## water_depth_m, elevation, elev_units, ## road_dist_m, water_dist_m, mean_ndvi, ## colours)` Lets explore two different types of plot we can make for once particular species, then we will challenge you to explore some relationships of your own. 8.7.1 Continuous predictors Scatter plots are very useful, we can easily make them with a trendline using ggplot. ggplot(data=total_obs, aes(x=line_of_sight_m, y=Alces.alces)) + geom_point() + # Specify a scatter plot theme_classic() + geom_smooth(method=lm, se=T, fullrange=TRUE) # A nice theme What do you think? For more ggplot scatterplot examples (with code) see the R graph gallery - Scatterplots. Let’s checkout another predictor: ggplot(data=total_obs, aes(x=mean_ndvi, y=Alces.alces)) + geom_point() + # Specify a scatter plot theme_classic() + geom_smooth(method=lm, se=T, fullrange=TRUE) # A nice theme 8.7.2 Catagorical predictors For categorical predictors boxplots are very useful! ggplot(total_obs, aes(x=feature_type, y=Alces.alces)) + geom_boxplot()+ theme_classic() For more ggplot boxplot examples (with code) see R Graph Galley - Boxplots. There is some cool stuff in there! 8.7.3 Do your own exploration We will now list some potential relationships in the data, you should decide the best way to explore each one: Wolves (Canis lupus) use locations with longer line_of_sight_m more frequently Caribou (Rangifer tarandus) use locations where the water table is close to the surface (low water_depth_m) White-tailed deer (Odocoileus virginianus) use locations with higher vegetation productivity (mean_ndvi) Lynx (Lynx canadensis) select human use feature types over other feature types Lynx (Lynx canadensis) select locations with higher snowshoe hare (Lepus americanus) activity Can you find any evidence to support these? Are there any other things that interest you? Remember we have the following species: ## [1] &quot;Cervus.canadensis&quot; &quot;Lontra.canadensis&quot; ## [3] &quot;Oryctolagus.cuniculus&quot; &quot;Canis.latrans&quot; ## [5] &quot;Vulpes.vulpes&quot; &quot;Martes.americana&quot; ## [7] &quot;Tamiasciurus.hudsonicus&quot; &quot;Lynx.canadensis&quot; ## [9] &quot;Canis.lupus&quot; &quot;Rangifer.tarandus&quot; ## [11] &quot;Alces.alces&quot; &quot;Ursus.americanus&quot; ## [13] &quot;Lepus.americanus&quot; &quot;Odocoileus.virginianus&quot; And the following covariates: ## [1] &quot;feature_type&quot; &quot;line_of_sight_m&quot; &quot;water_depth_m&quot; &quot;elevation&quot; ## [5] &quot;road_dist_m&quot; &quot;water_dist_m&quot; &quot;mean_ndvi&quot; "],["composition.html", "Chapter 9 Community composition 9.1 Observed richness 9.2 Estimated richness 9.3 Other diversity metrics 9.4 Community structure", " Chapter 9 Community composition By Christopher Beirne and Laura Stewart One of the most fundamental questions researchers and practitioners want to answer is how many species are there in my survey area?. Exploring patterns in species richness can also tell us if we have performed ‘enough’ surveying. Create a new .R script Call it 04_example_richness.R. Load the required packages # Check you have them and load them list.of.packages &lt;- c(&quot;iNEXT&quot;, &quot;kableExtra&quot;, &quot;tidyr&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;dplyr&quot;, &quot;viridis&quot;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) lapply(list.of.packages, require, character.only = TRUE) 9.1 Observed richness The simplest way to quantify species richness is counting the number of species you detect on your camera traps - ‘observed richness’. This is very easy to determine using our species list: sp_summary &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_species_list.csv&quot;, header=T) # Use nrow() to count the number of species nrow(sp_summary) ## [1] 14 In the case of the example data set, this represents 14 mammal species. class order family genus species sp common_name Mammalia Artiodactyla Cervidae Alces alces Alces.alces moose Mammalia Artiodactyla Cervidae Cervus canadensis Cervus.canadensis elk Mammalia Artiodactyla Cervidae Odocoileus virginianus Odocoileus.virginianus white-tailed deer Mammalia Artiodactyla Cervidae Rangifer tarandus Rangifer.tarandus caribou Mammalia Carnivora Canidae Canis latrans Canis.latrans coyote Mammalia Carnivora Canidae Canis lupus Canis.lupus gray wolf Mammalia Carnivora Canidae Vulpes vulpes Vulpes.vulpes red fox Mammalia Carnivora Felidae Lynx canadensis Lynx.canadensis canada lynx Mammalia Carnivora Mustelidae Lontra canadensis Lontra.canadensis river otter Mammalia Carnivora Mustelidae Martes americana Martes.americana american marten Mammalia Carnivora Ursidae Ursus americanus Ursus.americanus black bear Mammalia Lagomorpha Leporidae Lepus americanus Lepus.americanus snowshoe hare Mammalia Lagomorpha Leporidae Oryctolagus cuniculus Oryctolagus.cuniculus rabbit Mammalia Rodentia Sciuridae Tamiasciurus hudsonicus Tamiasciurus.hudsonicus red squirrel It is possible to compare observed richness across different strata of interest, however survey effort must be identical between your comparison strata. This very rarely the case in camera trap studies where cameras break, run out of battery or are deployed for different lengths of time. The number of species you detect is a function of the amount of effort you spent surveying/the number of individuals detected - the longer a camera is active/the more individuals detected, the more species it will detect. What this means is, unless you saturate a landscape with camera traps, observed richness will underestimate true richness. Consequently, We need ways of comparing species richness which accounts in some way for survey effort. 9.2 Estimated richness There are two commonly used ways to account for survey effort when estimating species richness using camera traps: using the incidence of rare species to ‘correct’ observed richness (iNext) using multispecies occupancy models to account for the species present but not observed (occupancy model) 9.2.1 iNext package The iNext package (INterpolation and EXTrapolation of species richness) - is both easy to use and rapid to compute. It also comes with a wealth of plotting functions - see the iNext Quick Introduction for a great walk through tutorial. Its core functionality is based on: Chao, Anne, et al. “Rarefaction and extrapolation with Hill numbers: a framework for sampling and estimation in species diversity studies.” Ecological monographs 84.1 (2014): 45-67. Which has, to date, been cited &gt;2000 times! 9.2.1.1 Sampling locations The iNEXT package gets really interesting when we start to compare multiple different strata. e.g. different treatment types or species groupings. The code to build a multi-strata comparison is very similar to that of a single strata, except now you separate the observations into their relevant categories/strata. We will compare the different categories using the feature_type column in the covariate file. We match the ‘placenames’ in our locations dataframe with the corresponding capture data in total_obs using the %in% command. # Load the packages library(iNEXT); library(ggplot2); library(gridExtra) # Use the total observations file total_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_total_observations.csv&quot;, header=T) # Format it into incidence data inc_dat &lt;- total_obs %&gt;% mutate(across(sp_summary$sp, ~+as.logical(.x))) # Turn species counts into 0&#39;s and 1&#39;s # Read in the locations data frame locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;) # We first want to create a data subset for each of the strata we are interested in: # The treatment types for each Deployment.Location.ID are in the sta file # Make an object containing all of the site ID&#39;s for the &quot;Offline&quot; cameras off &lt;- locs$placename[locs$feature_type==&quot;Offline&quot;] # And &quot;HumanUse&quot; cameras hum &lt;- locs$placename[locs$feature_type==&quot;HumanUse&quot;] # Create a new empty list inc_locations &lt;- list() # Each &quot;treatment&quot; is a separate element within the list inc_locations[[1]] &lt;- c(length(off), # First count the number of stations # Then subset the detections to those stations, sum the columns, and sort the incidents inc_dat[inc_dat$placename %in% off, sp_summary$sp] %&gt;% colSums() %&gt;% sort(decreasing=T)) inc_locations[[2]] &lt;- c(length(hum), # Count the number of stations # Then subset the detections to those stations, sum the columns, and sort the incidents inc_dat[inc_dat$placename %in% hum, sp_summary$sp] %&gt;% colSums() %&gt;% sort(decreasing=T)) # Give them names names(inc_locations) &lt;- c(&quot;Offline&quot;, &quot;HumanUse&quot;) # Run the iNEXT code out.inc &lt;- iNEXT(inc_locations, q=0, datatype=&quot;incidence_freq&quot;) # Sample‐size‐based R/E curves ggiNEXT(out.inc, type=1, color.var=&quot;Assemblage&quot;) + labs(y=&quot;Richness&quot;, x = &quot;Locations surveyed&quot;) + theme_classic() 9.2.2 Sampling duration example If we want to explore the species accumulation patterns as a function of the number of survey duration, we can make use of the ...weekly_observations dataframes. week_obs&lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_weekly_observations.csv&quot;, header=T) # Turn it into binary incidents inc_dat &lt;- week_obs %&gt;% mutate(across(sp_summary$sp, ~+as.logical(.x))) # Create a new empty list inc_time &lt;- list() # Only sum the data for each relevent strata inc_time[[1]] &lt;- c(nrow(inc_dat[inc_dat$placename %in% off,]), # Count the number of weeks we have data for in each strata # Then subset the detections to those stations, sum the columns, and sort the incidents inc_dat[inc_dat$placename %in% off, sp_summary$sp] %&gt;% colSums() %&gt;% sort(decreasing=T)) inc_time[[2]] &lt;- c(nrow(inc_dat[inc_dat$placename %in% hum,]), # Count the number of stations # Then subset the detections to those stations, sum the columns, and sort the incidents inc_dat[inc_dat$placename %in% hum, sp_summary$sp] %&gt;% colSums() %&gt;% sort(decreasing=T)) # Give them names names(inc_time) &lt;- c(&quot;Offline&quot;, &quot;HumanUse&quot;) # Run the model out.inc &lt;- iNEXT(inc_time, q=0, datatype=&quot;incidence_freq&quot;) # Sample‐size‐based R/E curves ggiNEXT(out.inc, type=1, color.var=&quot;Assemblage&quot;) + labs(y=&quot;Richness&quot;, x = &quot;Camera weeks&quot;) + theme_classic() Which suggests the same pattern as the site based example. 9.3 Other diversity metrics 9.3.1 Simpson and Shannon One issue with species richness assessments is that they weight all species equally, thus a community with 12 species all present in equal abundances will give you the same richness value as a high skewed community with one highly abundant species, and 11 very rare ones. Consequently, you might want to estimate species diversity. Luckily, the iNEXT package is well suited for comparisons of diversity indices through the use of hill numbers - of which the ‘q’ value represents the traditional Shannon (q=1) and Simpson (q=2) diversity indices (species richness: q = 0). Note Increasing values of q reduces the influence of rare species on your estimate of community diversity. For example, we might want to compare the species diversity across our two focal strata: # We also introduce the object t -&gt; which reflects the range of values over which you want to predict species richness out &lt;- iNEXT(inc_time, q=c(0,1,2) ,datatype=&quot;incidence_freq&quot; ) ggiNEXT(out, type=1, facet.var=&quot;Order.q&quot;, color.var=&quot;Assemblage&quot;) + theme_classic() 9.3.2 More examples in the literature Some examples of using iNEXT with camera trap data: Cusack et al. 2015 Random versus Game Trail-Based Camera Trap Placement Strategy for Monitoring Terrestrial Mammal Communities Kays et al. 2020 An empirical evaluation of camera trap study design: How many, how long and when? Semper-Pascual et a. 2018 Mapping extinction debt highlights conservation opportunities for birds and mammals in the South American Chaco Publishing note If you publish your work based on the results from the iNEXT package, you should make references to the following methodology paper (Chao et al. 2014) and the application paper (Hsieh, Ma &amp; Chao, 2016): Chao A, Gotelli NJ, Hsieh TC, Sande EL, Ma KH, Colwell RK, Ellison AM (2014). “Rarefaction and extrapolation with Hill numbers: a framework for sampling and estimation in species diversity studies.” Ecological Monographs, 84, 45–67. Hsieh TC, Ma KH, Chao A (2022). iNEXT: Interpolation and Extrapolation for Species Diversity. R package version 3.0.0, http://chao.stat.nthu.edu.tw/wordpress/software_download/. 9.3.3 Multispecies occupancy model It is also possible to estimate species richness in a given area/strata using multispecies occupancy models. For an example with code in the appendices see: Tobler, M. et al. Spatiotemporal hierarchical modelling of species richness and occupancy using camera trap data. J. Appl. Ecol. (2015). 9.4 Community structure One of the shortfalls in the diversity index approaches is that you can compare two sites with completely different mammal assemblages, but identical diversity estimates! So we would conclude that the two are the same, however,in reality their compositions are totally different. Another way to assess community structure is with ordination methods (e.g non-metric multidimensional scaling or NMDS). For a fantastic (although now somewhat dated) blog on NMDS methods see: Sample(ecology)’s NMDS tutorial in R. Luckily a basic NMDS is very easy to run from our ...total_observations dataframe: #install.packages(&quot;vegan&quot;) library(vegan) # Import your count data total_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_total_observations.csv&quot;, header=T) #Import the location and covariate data locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;) # Add the covariates to your total_obs dataframe dat &lt;- left_join(total_obs, locs) # Convert to categorical factors dat &lt;- dat %&gt;% mutate_if(is.character,as.factor) # Subset to just the count columns counts &lt;- dat[,sp_summary$sp] # Covert it into a matrix m_counts &lt;- as.matrix(counts) # Run the model set.seed(123) # To make sure we all get the same result # run metaMDS on the count matrix using the &quot; Bray-Curtis dissimilarity&quot; note others are available nmds = metaMDS(m_counts, # The count matrix distance = &quot;bray&quot;, # The method of solving trace=0) # Supress the output - trace=1 is more informative 9.4.1 Extracting data for plotting To make a nice plot of the NMDS data we need to learn how to extract the data from it: # Make a dataframe out of the x and Y scores site.scores &lt;- as.data.frame(scores(nmds)$sites) species.scores &lt;- as.data.frame(scores(nmds)$species) # Add in the covariate data #add covariate columns to data frame site.scores$placename &lt;- dat$placename site.scores$feature_type &lt;- dat$feature_type # Assign colors to our feature_types using viridis # then use the turbo() function to assign each level a color col.cat &lt;- cividis(length(levels(dat$feature_type))) # then we apply it to the dataframe dat$colours &lt;- col.cat[dat$feature_type] # Plot the result par(mfrow=c(1,1)) # Make an empty plot type=&quot;n ordiplot(nmds,type=&quot;n&quot;, las=1, xlim=c(-1.5,1.2)) # Add an elipse corresponding to each site ordiellipse(nmds, groups=dat$feature_type, col=col.cat, lwd=2) # Add the species loadings orditorp(nmds,display=&quot;species&quot;,col=&quot;red&quot;,air=0.5) # Add the site loadings points(site.scores$NMDS1, site.scores$NMDS2, col=dat$colours, pch=19) # Add a legend legend(&quot;topleft&quot;, levels(dat$feature_type), col=col.cat, pch=19 ) The different feature_types to not differ majorly in their species compositions - there is a huge degree of overlap between sites. The NMDS framework is flexible - we can also add environmental covariates using envfit to explain differences we might find. Checkout a great blog on this by Jackie Zorz for more information! 9.4.2 Examples in the literature Haysom, J. K., Deere, N. J., Wearn, O. R., Mahyudin, A., Jami, J. B., Reynolds, G., &amp; Struebig, M. J. (2021). Life in the Canopy: Using Camera-Traps to Inventory Arboreal Rainforest Mammals in Borneo. Frontiers in Forests and Global Change, 83 Note - they also use iNext! Give that paper a look! "],["habitat-use.html", "Chapter 10 Habitat use 10.1 Calculating capture rate 10.2 Single-species models 10.3 Multispecies models", " Chapter 10 Habitat use Camera traps are well suited for the quantification of habitat use across multiple species. To assess habitat use, we typically quantify the detection rate - the number of detections divided by the time interval of interest. As detection rates are fairly simple to estimate and conceptually simple to understand, thus their use is widespread in the camera trap literature. In its simplest form habitat use represents the number of independent events of a given species at a given camera, divided by the number of days that camera was active during that period of interest. This ‘detection rate’ is thought to reflect the habitat use of a species at a given location. Extreme care should be taken if you want to equate use with abundance or density - something we discuss a little more in the density chapter. Detection rates are typically analysed in a linear modelling framework, and come in single species and multi-species versions (see below). Create a new .R script Call it 05_example_habitat_use.R. Load the required packages # Check you have them and load them list.of.packages &lt;- c(&quot;kableExtra&quot;, &quot;tidyr&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;lme4&quot;, &quot;dplyr&quot;, &quot;Hmsc&quot;, &quot;jtools&quot;, &quot;lubridate&quot;, &quot;corrplot&quot;, &quot;MuMIn&quot;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) lapply(list.of.packages, require, character.only = TRUE) 10.1 Calculating capture rate We will start by using the total_obs dataframe we have used in previous chapters: # Import the total observations dataset total_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_total_observations.csv&quot;, header=T) # Import your species list sp_summary &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_species_list.csv&quot;, header=T) # Create a dataframe to store these detection rates total_cr &lt;- total_obs # Divide the species abundances (which start in column four), by the amount of camera effort total_cr[ ,sp_summary$sp ] &lt;- (total_cr[ , sp_summary$sp]/total_cr$days)*100 # Make a plot of observations vs. capture rate plot(total_cr$Odocoileus.virginianus ~ total_obs$Odocoileus.virginianus, las=1, pch=19, ylab=&quot;Capture rate per 100 days&quot;, xlab=&quot;Number of independent records&quot;) As you can see there is not a perfect match as the capture rate accounts for the variation in effort between different sites. 10.1.1 Examples from the literature Palmer, Meredith S., et al. “Evaluating relative abundance indices for terrestrial herbivores from large‐scale camera trap surveys.” African journal of ecology 56.4 (2018): 791-803. 10.2 Single-species models The most common way to analyse habitat-use data is through linear models. Linear models typically relate a continuous response variable - in our case capture rate - to a set of one or more discrete or continuous predictor variables. In this simple example we will explore the relationship between the capture rate of a species with the categorical ‘feature_type’ variable and the continuous line_of_sight_m variables. There are a variety if different frameworks to fit and compare different linear models to address a host of different hypotheses, but if you are just starting out you should investigate two widely used packages: lme4 -&gt; frequentest and information theoretic approaches brms -&gt; Bayesian approaches There is no right or wrong about which package and which approach you use to test your hypotheses. Some packages have functionalities that others don’t, which may force your hand. Just make sure you understand the implications of your choices when it comes to reporting your results! 10.2.1 Simple linear model We will start by analyzing a frequentest linear model with a single observation for each camera location. In this worked example we will analyse how habitat use varies using a linear model lm(). The model takes the form: Response term (y) ~ fixed effect 1 (x1) + fixed effect 2 (x2), data frame (data=) It is beyond the scope of this course to test the model assumptions or interrogate the findings, there are better resources to allow you to do that (e.g. we highly recommend reading Gałecki, Andrzej, and Tomasz Burzykowski. “Linear mixed-effects model.” Linear mixed-effects models using R. Springer, New York, NY, 2013. 245-273). In this example we will explore if the habitat use of Odocoileus virginianus varies based on the `feature_type’ the line of sight where it is found. Preparing our data Recall that the information about each location is recorded in the file: # Import locations locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;, header=T) # Convert to categorical factors locs &lt;- locs %&gt;% mutate_if(is.character,as.factor) # Standardize # You should also standardize your covariates - it helps models coverage an facillitates comparison of effects sizes library(MuMIn) z_locs &lt;- stdize(locs) # Add the covariate data to the capture rate datframe mod_dat &lt;- left_join(total_cr, z_locs) # from the dplyr package ## Joining with `by = join_by(placename)` 10.2.2 Catagorical predictor So we start by exploring the influence of ‘feature_type’ on our response term. feature_type is a a categorical variable which reflects strata where the camera trap was deployed: HumanUse = a camera on a seismic line used and maintained in an “open” state by humans Offline = a camera in contiguous forest &gt;200m from a seismic line NatRegen = a seismic line which is naturally regenerating Lets do a quick raw data plot to see what results we might expect: boxplot(mod_dat$Odocoileus.virginianus~mod_dat$feature_type, las=1, xlab=&quot;feature_type&quot;, ylab=&quot;Habitat use&quot;) It looks like white-tailed deer habitat use may be higher in naturally regenerating areas, but there is a lot of overlap between sites. Next we will fit a simple linear model using the `lm()’ function in base R. # model results &lt;- lm( Y data ~ x Data, data= dataframe source) lm_cat &lt;- lm(Odocoileus.virginianus ~ feature_type, data = mod_dat) # And check the output summary(lm_cat) ## ## Call: ## lm(formula = Odocoileus.virginianus ~ feature_type, data = mod_dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.8377 -2.5572 -0.9958 1.4862 7.4681 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.1645 0.8838 1.318 0.1962 ## feature_typeNatRegen 2.6732 1.3324 2.006 0.0526 . ## feature_typeOffline 2.1782 1.2737 1.710 0.0961 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.307 on 35 degrees of freedom ## Multiple R-squared: 0.1208, Adjusted R-squared: 0.07061 ## F-statistic: 2.405 on 2 and 35 DF, p-value: 0.105 Categorical covariates are show as contrasts from the reference level (in this case HumanUse), and the p-value relate to testing whether the other categories are significantly different from the reference level. Other things to note are that our R-squared value (how much variation the model explains) is fairly low - but that is common in camera trap models. We can take a quick look at the predictions using the jtools package. More examples of its use are can be found in the `Visualizing regression model predictions vignette associated with the package. effect_plot(lm_cat, # The model object pred = feature_type, # The variable you want to predict interval = TRUE, # Whether you want confidence intervals (default = 0.95) partial.residuals = T, # Show the residual variation -after accounting for fixed effects y.label = &quot;Habitat use&quot;) # Change the y axis label 10.2.3 Continuous predictor Let’s also explore a continuous predictor line_of_sight_m': We will fit a simple linear model using thelm()’ function in base R. # model results &lt;- lm( Y data ~ x Data, data= dataframe source) lm_con &lt;- lm(Odocoileus.virginianus ~ z.line_of_sight_m, data = mod_dat) # Look at the output summary(lm_con) ## ## Call: ## lm(formula = Odocoileus.virginianus ~ z.line_of_sight_m, data = mod_dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.9177 -2.7046 -0.5994 1.6422 7.0377 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.6835 0.5157 5.203 8.06e-06 *** ## z.line_of_sight_m -1.3898 0.5227 -2.659 0.0116 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.179 on 36 degrees of freedom ## Multiple R-squared: 0.1642, Adjusted R-squared: 0.141 ## F-statistic: 7.071 on 1 and 36 DF, p-value: 0.01162 Here the effect represents the gradient of the relationship between line_of_sight_m and the habitat use of white-tailed deer. The effect is negative, and the p-value is below the arbitrary 0.05 threshold, which suggests it my be an important predictor of white-tailed deer habitat use. It will make more sense if we plot it - again using jtools effect_plot(lm_con, # The model object pred = z.line_of_sight_m, # The variable you want to predict interval = TRUE, # Whether you want confidence intervals (default = 0.95) partial.residuals = T, # Show the residual variation -after accounting for fixed effects y.label = &quot;Habitat use&quot;) # Change the y axis label 10.2.4 Model comparisons There are times when we may want to compare which model is “the best”, or which model is the most parsimonious. One way to do this is through the use of Information Theory - we can compare which model explains the most amount of variation after applying a penalty for how complex it is (more complex models will always explain more variation, even if just by chance). One useful package for this is the MuMIn package and the function model.sel() for model selection: library(MuMIn) # Lets also create a &quot;null model&quot; something without any predictors in at all, to compare these models to: lm_null &lt;- lm(Odocoileus.virginianus ~ 1, data = mod_dat) # Compare the results model.sel(lm_null, lm_cat, lm_con) ## Model selection table ## (Int) ftr_typ z.lin_of_sgh_m df logLik AICc delta weight ## lm_con 2.683 -1.39 3 -96.844 200.4 0.00 0.821 ## lm_cat 1.164 + 4 -97.805 204.8 4.43 0.090 ## lm_null 2.683 2 -100.252 204.8 4.45 0.089 ## Models ranked by AICc(x) Whilst both models improve on the null model, there is stronger support for line_of_sight_m than for our feature types in influencing white-tailed deer habitat use. Cool! 10.2.5 Problems with these models But can you see any problems with this type of model? We probably should be concerned about the fact that: There are negative predictions for both sets of confidence intervals - but you can’t get a negative capture rate! We do not account for seasonality - we saw species detection rates change with time of year in the data exploration section And more besides! 10.2.6 Mixed-effects models Let’s build a more robust habitat-use model which addresses some of the issues highlighted here. To do this we will take advantage of a type of analysis called ‘mixed effects modelling’. Mixed effects models allow us to perform robust analysis of populations which have been repeatedly sampled through time. As such, we can break our data set down into months without violating the assumptions of the models. If you are new to mixed effects models you must try this fantastic interactive aid to help you understand how they work: Michael Freeman’s ‘An Introduction to Hierarchical Modeling’ And for a deep-dive into the inner workings of mixed effects models and their assumptions, see the following paper: Harrison, Xavier A., et al. “A brief introduction to mixed effects modelling and multi-model inference in ecology.” PeerJ 6 (2018): e4794. First we must install the packages we require: ‘lme4’ and `tidyr’: library(lme4); library(tidyr) # Import the monthly observations dataset monthly_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_monthly_observations.csv&quot;, header=T) # Add the locations (as before) mod_dat &lt;- left_join(monthly_obs, z_locs) ## Joining with `by = join_by(placename)` # extract month from the data frames mod_dat$date &lt;- ym(mod_dat$date) mod_dat$month&lt;- month(mod_dat$date, label=T) # Convert month into a simple summer and winter comparison mod_dat$season &lt;- &quot;summer&quot; mod_dat$season[month(mod_dat$date) %in% c(10,11,12,1,2,3)] &lt;- &quot;winter&quot; # make it a factor mod_dat &lt;- mod_dat %&gt;% mutate_if(is.character,as.factor) # Run the model glmm_cat &lt;- glmer.nb(Odocoileus.virginianus ~ feature_type + season + offset(log(days)) + (1|placename) , data=mod_dat) # Check the model fit summary(glmm_cat) ## Generalized linear mixed model fit by maximum likelihood (Laplace ## Approximation) [glmerMod] ## Family: Negative Binomial(0.8362) ( log ) ## Formula: Odocoileus.virginianus ~ feature_type + season + offset(log(days)) + ## (1 | placename) ## Data: mod_dat ## ## AIC BIC logLik deviance df.resid ## 1337.6 1364.9 -662.8 1325.6 691 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -0.8336 -0.4267 -0.1919 -0.1210 6.5197 ## ## Random effects: ## Groups Name Variance Std.Dev. ## placename (Intercept) 3.758 1.939 ## Number of obs: 697, groups: placename, 38 ## ## Fixed effects: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.7986 0.6205 -9.345 &lt;2e-16 *** ## feature_typeNatRegen 1.9662 0.8612 2.283 0.0224 * ## feature_typeOffline 1.0860 0.8379 1.296 0.1949 ## seasonwinter -0.4427 0.1566 -2.827 0.0047 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ftr_NR ftr_tO ## ftr_typNtRg -0.695 ## ftr_typOffl -0.694 0.497 ## seasonwintr -0.073 -0.011 -0.008 We can plot the predictions from these models using the jtools package. First lets look at the effects of feature_type: effect_plot(glmm_cat, pred = feature_type, interval = TRUE, y.label = &quot;Habitat use&quot;, , data=mod_dat) ## Outcome is based on a total of 1 exposures ## Confidence intervals for merMod models is an experimental feature. The ## intervals reflect only the variance of the fixed effects, not the random ## effects. As with our simple linear model, the mixed effects model also suggests a difference between the different feature_type strata for white-tailed deer. Lets also look at the effect of our new season variable: effect_plot(glmm_cat, pred = season, interval = TRUE, y.label = &quot;Habitat use&quot;, , data=mod_dat) Which suggests habitat use is slightly lower habitat use in winter then in summer. 10.2.7 Advanced mixed-model predictions Tools such as jtools are great for generating simple predictions from mixed models, however the more complex the models get, the more you may want to specify your own prediction dataframes. If you want more applied examples of generating predictions from mixed effects models, check out Ben Bolkers workbook. There is also some great discussion about model selection and r-squared values. 10.2.8 Examples in the literature Tattersall, E. R., Burgar, J. M., Fisher, J. T., &amp; Burton, A. C. (2020). Mammal seismic line use varies with restoration: Applying habitat restoration to species at risk conservation in a working landscape. Biological Conservation, 241, 108295. 10.3 Multispecies models In the above examples, we analyse each individual species separately. This is great if you only care about one species, however we often want a more holistic understanding of wildlife communities! Recent advances in computer power and analytic approaches mean it is becoming increasingly popular to model multiple species within the same framework! This opens up a variety of things not previously possible. A note of caution In experimenting with single species models you may have realized it can sometimes be hard to build a sensible and robust model. Now do this for &gt;10 species in the same model, and the potential to get silly results increases. Tread carefully! As with single species linear models, there are many choices available for modeling multiple species in the same framework. Two notable options are: GJAM HMSc In this example we will use the Hmsc package. library(Hmsc) # Prepare our data # Pull the count data into its own matrix Y &lt;- as.matrix(monthly_obs[,sp_summary$sp]) # Give the row names a useful label, in this case the site_date values # (just in case you want to check things) row.names(Y) &lt;- paste(monthly_obs$placename, monthly_obs$date, sep=&quot;_&quot;) # Join with the location data Xdat &lt;- left_join(monthly_obs[c(&quot;placename&quot;, &quot;date&quot;, &quot;days&quot;)], z_locs) # All XData must be numeric or factors, so lets check what we have # Set up the sampling conditions nChains = 2 # How many total repeats to run thin = 5 # How often to thin the samples samples = 100 # How many samples to take transient = 200 # How long should the &quot;warm up&quot; be verbose = T # Give reports on model progress # Specify the random effects # Add a station-level random effect (for the co-variances) studyDesign = data.frame(station = as.factor(Xdat$placename)) rL = HmscRandomLevel(units = studyDesign$station) # Model specification mod &lt;- Hmsc(Y = Y, XData = Xdat[,c(&quot;z.line_of_sight_m&quot;, &quot;z.water_depth_m&quot;, &quot;days&quot;)], XFormula = ~z.line_of_sight_m + z.water_depth_m + log(days), studyDesign = studyDesign, ranLevels = list(station = rL), distr=&quot;poisson&quot;) # Fit the model out &lt;- sampleMcmc(mod, thin = thin, samples = samples, transient = transient, nChains = nChains, verbose = verbose) We can plot a basic summary of the modeled effects using the following code. postBeta = getPostEstimate(out, parName = &quot;Beta&quot;) par(mar=c(8,12,1,1)) plotBeta(out, post = postBeta, param = &quot;Support&quot;, supportLevel = 0.95) We the colors denote the size and magnitude of the effect of proportion of lowland habitat. NOTE treat these results with caution as the number of model runs is very low (to increase speed) and the model assumptions have not been interrogated. OmegaCor = computeAssociations(out) supportLevel = 0.0 toPlot = ((OmegaCor[[1]]$support&gt;supportLevel) + (OmegaCor[[1]]$support&lt;(1-supportLevel))&gt;0)*OmegaCor[[1]]$mean corrplot(toPlot, method = &quot;color&quot;, type=&quot;upper&quot;, order = &quot;FPC&quot;, col = colorRampPalette(c(&quot;blue&quot;,&quot;white&quot;,&quot;red&quot;))(200), title = paste(&quot;random effect level:&quot;, mod$rLNames[1]), mar=c(0,0,1,0)) 10.3.1 Potential dangers The analysis has worked and we have some really stylish output! But - take screenshots of the output and run it again. Compare your screen shots. Bayesian solvers don’t work the same way as frequentist approaches. With frequentist approaches you get the same result every time, with bayesian approaches a solver explores the parameter space to “find” the right solution. If you do not give time for the solver to coverage on the right solution, you will get a result that is not in the slightest bit reliable! For a nice overview on assessing Bayesian model convergence see Michael Clark’s bayseian model diagnostics page. Let’s have a look at our traceplots - these are plots which show the Bayesian solvers efforts to converge on the answer for each parameter with each iteration of the model (red and black done the different runs). If they have converged on a solution they should be steady and stable, the coloured lines on the left should overlap and the density plot on the right should be uni-modal. First for the fixed effects in the model: mpost = convertToCodaObject(out) plot(mpost$Beta) What do you think? These sampling chains will have to be much longer for these models to converge! 10.3.2 Further reading The best place for examples of HMSC analyses right now are package vignettes: Getting started with HMSC-R: univariate models Getting started with HMSC-R: low-dimensional multivariate models Getting started with HMSC-R: high-dimensional multivariate models Getting started with HMSC-R: spatial models 10.3.3 Examples in the literature Carvalho Jr, Elildo AR, et al. “Effects of illegal logging on Amazonian medium and large-sized terrestrial vertebrates.” Forest Ecology and Management 466 (2020): 118105. Beirne, Christopher, et al. “Multispecies modelling reveals potential for habitat restoration to re‐establish boreal vertebrate community dynamics.” Journal of Applied Ecology 58.12 (2021): 2821-2832. "],["occupancy.html", "Chapter 11 Occupancy 11.1 Single species occupancy model", " Chapter 11 Occupancy Occupancy modelling has been one of the mainstays of camera traps data analysis for many years, so learning how to wangle our data into occupancy-style formats is essential. When we survey wild and free ranging populations using any sampling methodology, the probability of detecting a given individual or species if it is actually present on the landscape at the time of sampling is typically less than one. This is because wild animals are often hard to see! This issue is termed “imperfect detection”. In order to deal with the imperfect detection issue - occupancy models separate our the counts of a given species at a site into two processes: occupancy (ψ) - which is the probability of a species occurring within a spatial unit (or “site”) during the sampling session detection probability (p) - the probability that the species will be detected given that it already occurs at a site In order to separate out the occupancy process from the detection process, surveys need to occur at replicated ‘sites’ and we need repeated ‘visits’ to the same site. It is important to know that in camera trap studies, practitioners typically treat individual locations as sites and rather than repeated return to a location to survey it at different times, they divide the continuous camera activity data into block of time (e.g. 1 to 7 day windows). Occupancy models were not developed specifically for camera traps - thus there are a suite of assumptions we need to make about the populations we survey when applying occupancy models. We do not adress these here. However, below we provide a list introductory resources for you to dig into the occupancy models to decide if they are appropriate for your situation: Burton, A. Cole, et al. “Wildlife camera trapping: a review and recommendations for linking surveys to ecological processes.” Journal of Applied Ecology 52.3 (2015): 675-685. MacKenzie, Darryl I., et al. Occupancy estimation and modeling: inferring patterns and dynamics of species occurrence. Elsevier, 2017. Let’s focus our time on getting our data into the right formt, and applying some occupancy models! # Check you have them and load them list.of.packages &lt;- c(&quot;kableExtra&quot;, &quot;tidyr&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;dplyr&quot;, &quot;unmarked&quot;, &quot;lubridate&quot;, &quot;tibble&quot;, &quot;sf&quot;, &quot;gfcanalysis&quot;, &quot;MuMIn&quot;, &quot;spOccupancy&quot;) new.packages &lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,&quot;Package&quot;])] if(length(new.packages)) install.packages(new.packages) lapply(list.of.packages, require, character.only = TRUE) 11.1 Single species occupancy model In this example we will use the ...weekly_observations dataframe we created in the data creation section. We do this because 7 days is a time interval which occupancy models are often devided into for occupancy analyses. We first need to create a site by occasion matrix for our focal species, using a 7-day occasion length. This means we need to break our camera data into seven day bins. # Import the weekly observations data set week_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_weekly_observations.csv&quot;, header=T) # Use white-tailed deer as an example focal_sp&lt;- &quot;Odocoileus.virginianus&quot; # subset to just the 2019 data tmp_week &lt;- week_obs[substr(week_obs$date,1,4)==2019,] # Create the Y data y_dat &lt;- tmp_week[,c(&quot;placename&quot;, &quot;date&quot;, focal_sp)] %&gt;% # Subset to just white-tailed deer pivot_wider(names_from = date, values_from = focal_sp) # Shift to wide format ## Warning: Using an external vector in selections was ## deprecated in tidyselect 1.1.0. ## ℹ Please use `all_of()` or `any_of()` ## instead. ## # Was: ## data %&gt;% select(focal_sp) ## ## # Now: ## data %&gt;% select(all_of(focal_sp)) ## ## See ## &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This warning is displayed once every 8 ## hours. ## Call `lifecycle::last_lifecycle_warnings()` ## to see where this warning was generated. # Convert it to a matrix - but only keep the date values y_mat &lt;- as.matrix(y_dat[,unique(tmp_week$date)]) # Update the row names row.names(y_mat) &lt;- y_dat$placename The resulting data frame looks like this: 2019-W00 2019-W01 2019-W02 2019-W03 2019-W04 2019-W05 2019-W06 2019-W07 2019-W08 2019-W09 2019-W10 2019-W11 2019-W12 2019-W13 2019-W14 2019-W15 2019-W16 2019-W17 2019-W18 2019-W19 2019-W20 2019-W21 2019-W22 2019-W23 2019-W24 2019-W25 2019-W26 2019-W27 2019-W28 2019-W29 2019-W30 2019-W31 2019-W32 2019-W33 2019-W34 2019-W35 2019-W36 2019-W37 2019-W38 2019-W39 2019-W40 2019-W41 2019-W42 2019-W43 2019-W44 2019-W45 2019-W46 ALG027 0 0 0 0 0 0 0 0 0 0 0 0 0 0 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ALG029 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 1 1 4 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 1 3 1 1 0 ALG031 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG032 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG035 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG036 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG037 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG038 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG039 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG043 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 2 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 ALG044 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 ALG045 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG046 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG047 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 1 1 0 0 0 0 0 2 0 0 2 0 0 0 0 0 0 NA NA NA NA NA NA NA NA NA NA NA NA ALG048 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 ALG049 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 NA NA NA NA NA NA NA ALG052 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 3 1 2 0 0 1 1 5 0 0 1 0 2 3 1 1 1 1 1 0 0 0 2 1 3 0 1 1 0 ALG053 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG054 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 2 0 0 1 1 1 1 1 0 0 0 2 2 4 ALG055 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 2 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 ALG056 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 ALG057 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 6 0 ALG058 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 1 1 4 1 2 4 3 2 2 2 3 1 4 6 4 0 2 0 0 0 0 0 0 0 0 0 ALG059 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG060 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG061 0 1 0 0 1 2 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 2 1 ALG062 0 3 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 2 0 0 3 1 3 2 3 1 0 1 0 0 0 0 0 5 1 1 1 0 0 0 0 0 0 0 0 0 0 ALG063 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 1 1 1 0 0 1 1 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1 ALG064 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG065 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ALG066 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG067 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG068 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG069 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 3 1 0 1 0 0 0 0 0 0 2 0 0 3 4 1 0 2 1 3 1 0 0 1 1 2 3 5 0 0 2 1 ALG070 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ALG071 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 2 0 0 1 0 0 1 0 0 1 0 2 0 0 4 1 0 1 0 0 2 0 2 1 0 0 1 ALG072 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ALG073 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 It is a matrix of all the weeks the cameras were active, and whether the count of the independent detections in that interval. The fill = NA command puts a zero where there is data for a given day. You can see that in some columns we have values &gt; 1 - this is because we had more than one independent observation in that week. Occupancy analyses (typically) require this data to be in detection/non-dection (0 or 1) format. So lets change that here and add back in our effort data. # Where y_mat is &gt; 1, and where y_mat isn&#39;t NA - give it the value 1 y_mat[y_mat&gt;1 &amp; is.na(y_mat)==F] &lt;- 1 # Effort matrix # To create the effort matrix - inst of the Focal Species bring in the effort eff_mat &lt;- tmp_week[,c(&quot;placename&quot;, &quot;date&quot;, &quot;days&quot;)] eff_mat &lt;- eff_mat %&gt;% # Create a matrix based on dates and effort spread(date,days, fill = NA) %&gt;% # group by deloyment Location ID, then make that the row.namesd group_by(placename) %&gt;% column_to_rownames( var = &quot;placename&quot;) eff_mat &lt;- as.matrix(eff_mat) # Remove all of the data from the weeks where we did not get a complete sample: y_mat[eff_mat!=7] &lt;- NA Now we are ready to feed this into the unmarked package. 11.1.1 Unmarked package One of the hurdles in using the unmarked package is it uses a different style of dataframe called an unmarked dataframe. It is essentially a compillation of the different dataframes we need for the analysis (y data and covariate data). We asemmbled the Y data above, so now lets make the covariates: locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;) # Unmarked wants your detection history, effort data and site covariates as matrices. But the order is important! # Check the order of your matrices and covariates files matches... or you will get nonsense! table(locs$placename == row.names(y_mat)) ## ## TRUE ## 38 # Standardise you explanatory variables library(MuMIn) z_locs &lt;- stdize(locs) # Build an unmarkedFramOccu un_dat &lt;- unmarkedFrameOccu(y = y_mat, # your occupancy data siteCovs = z_locs) # Your site covariates ## Warning: siteCovs contains characters. Converting them to factors. # Fit a basic model m0 &lt;- occu(formula = ~1 # detection formula first ~1, # occupancy formula second, data = un_dat) # View the results summary(m0) ## ## Call: ## occu(formula = ~1 ~ 1, data = un_dat) ## ## Occupancy (logit-scale): ## Estimate SE z P(&gt;|z|) ## 0.668 0.345 1.94 0.0527 ## ## Detection (logit-scale): ## Estimate SE z P(&gt;|z|) ## -1.37 0.0749 -18.3 1.34e-74 ## ## AIC: 1170.366 ## Number of sites: 38 ## optim convergence code: 0 ## optim iterations: 26 ## Bootstrap iterations: 0 The estimate you see for both occupancy and detection probability is on the log-link scale. If we want to calculate the occupancy probability, we can use the backTransform() function: backTransform(m0, type = &quot;state&quot;) ## Backtransformed linear combination(s) of Occupancy estimate(s) ## ## Estimate SE LinComb (Intercept) ## 0.661 0.0773 0.668 1 ## ## Transformation: logistic So the probability that a white-tailed deer occupies one of the survey locations is ~0.66. For the detection probability we specify “det”: backTransform(m0, type = &quot;det&quot;) ## Backtransformed linear combination(s) of Detection estimate(s) ## ## Estimate SE LinComb (Intercept) ## 0.203 0.0121 -1.37 1 ## ## Transformation: logistic The probability that we detect a white-tailed deer in a given unit of time (7-days), given that it is there to be detected, is ~0.2. Let’s fit a couple of other models! First with a continuous covariate on the occupancy probability, then a categorical one too: # Occupancy is influence by line of sight m1 &lt;- occu(formula = ~1 # detection formula first ~z.line_of_sight_m, # occupancy formula second, data = un_dat) # Occupancy is influenced by the feature_type a camera is deployed on m2 &lt;- occu(formula = ~1 # detection formula first ~feature_type, # occupancy formula second, data = un_dat) # Perform model selection to find the best one model.sel(m0,m1,m2) ## Model selection table ## p(Int) psi(Int) psi(z.lin_of_sgh_m) psi(ftr_typ) df logLik AICc delta ## m1 -1.368 0.70530 -0.5664 3 -581.839 1170.4 0.00 ## m0 -1.368 0.66830 2 -583.183 1170.7 0.33 ## m2 -1.367 0.01785 + 4 -581.769 1172.8 2.37 ## weight ## m1 0.464 ## m0 0.394 ## m2 0.142 ## Models ranked by AICc(x) The best supported model contains z.line_of_sight_m, although the improvement on the null model is minimal. 11.1.2 Plotting predictions We can observe the relationship between our covariates and our occupancy probabilities through the use of a dummy dataframes (which we will call new_dat). A dummy dataframe is essential just a dataframe built up of dummy data - which lies within the upper and lower limits of the covariates we already have. We wouldn’t want to extrapolate beyond our data! We can then plot the results: # Generate new data to predict from new_dat &lt;- cbind(expand.grid( z.line_of_sight_m=seq(min(z_locs$z.line_of_sight_m),max(z_locs$z.line_of_sight_m), # add more covariates here if the model is more complex length.out=25))) # Make the predicted values for the data you supplied new_dat &lt;- predict(m1, type=&quot;state&quot;, newdata = new_dat, appendData=TRUE) #Plot the results p1 &lt;- ggplot(new_dat, aes(x = z.line_of_sight_m, y = Predicted)) + # mean line geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.5, linetype = &quot;dashed&quot;) + #Confidence intervals geom_path(linewidth = 1) + labs(x = &quot;Line of sight&quot;, y = &quot;Occupancy probability&quot;) + # axis labels theme_classic() + coord_cartesian(ylim = c(0,1)) p1 As with our habitat use model, white-tailed deer (Odocoileus virginianus) occupancy appears to decrease with increasing line of sight. 11.1.3 On your own Let’s explore some of the models we fit in the habitat use chapter in the occupancy framework. We have not included any detection covariates in this example dataset, so hold that constant for now! "],["activity.html", "Chapter 12 Activity 12.1 Independent detections or raw data? 12.2 Data formatting 12.3 Species comparisons 12.4 Treatment comparisons 12.5 Selected further reading", " Chapter 12 Activity Given that camera traps operate 24 hours a day, 7 days a week, and can record animal motion down to second-level precision, they represent a powerful tool to explore and contrast the activity patterns of the species they detect! Such analyses can give insight into competition, predation and coexistence. Characterizing the “activity level” - the proportion of the day which animals are active - is also increasingly important for new estimators of animal density (see the density chapter for more info). Consequently, understanding how to derive and use activity data is very important for people using camera traps. Must read Frey, Sandra, et al. “Investigating animal activity patterns and temporal niche partitioning using camera‐trap data: Challenges and opportunities.” Remote Sensing in Ecology and Conservation 3.3 (2017): 123-132. Two key packages overlap https://cran.r-project.org/web/packages/overlap/index.html activity https://cran.r-project.org/web/packages/activity/index.html They each use the timestamps in camera trap detetions to derive activity indices which can be compared between different strata of interest (e.g. species, treatments etc.). Here we will use the activity package. 12.1 Independent detections or raw data? A recent paper has highlighted that we need to carefully consider our data source for activity analyses: Christopher Peral, Marietjie Landman, Graham I. H. Kerley The inappropriate use of time-to-independence biases estimates of activity patterns of free-ranging mammals derived from camera traps Ecology and Evolution Whilst we typically use “independent data” for most of our camera trap analysis, doing so may throw away useful data on activity. Both in terms of the number of data points (power) but also the activity patterns they generate. Peral et.al show that 70% of papers published to date use independent data to derive their indices. They actually state:“We conclude that the application of time-to-independence data filters in camera trap-based estimates of activity patterns is not valid and should not be used.” So we will use the raw data to derive our indices! Load your packages 12.2 Data formatting First, lets import the processed raw data file. # Import the data img &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_raw_detections.csv&quot;, header=T) # Load the activity package library(activity) # Specify the timezone (if your camera doesn&#39;t correct for timezones, just use UTC) img$timestamp &lt;- ymd_hms(img$timestamp, tz=&quot;UTC&quot;) Note - find your timezone code for the tz= call here. 12.2.1 Accounting for sunrise and sunset A recent paper highlighted the challenges in trying to understand animal activity patterns at high latitudes - as sunrise/sunset timings vary substantially through the calender year. See: Vazquez, Carmen, et al. “Comparing diel activity patterns of wildlife across latitudes and seasons: Time transformations using day length.” Methods in Ecology and Evolution 10.12 (2019): 2057-2066. If we want to compare activity patterns between two different locations, or different seasons, the day length at the time the detection occurred can have a huge impact on our estimates of wildlife activity. For example, if we wanted to compare day/night activity between winter and summer periods, in winter animal activity is constrained to a much shorter day length. Fortunately, the authors have a solution! The average anchoring method Instead of using the ‘human’ 24h clock, we can instead express animal activity relative to an important anchor point in the day (e.g. sunrise). NOTE -the transformation is not necessary at latitudes below 20°, or in studies with a duration of less than a month (below 40° latitude), as day length doesn’t change substantially. # We need to add latitude and longitude to our observations # import our station locations (and other covariates) locs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_camera_locations_and_covariates.csv&quot;) # Add them to our data frame img_locs &lt;- left_join(img, locs) # calculate solar time tmp &lt;- solartime ( img_locs$timestamp, # the date time column img_locs$latitude, # Latitude img_locs$longitude, # Longitude tz=-6, # an offset in numeric hours to UTC (Alberta is 6 hours behind) format=&quot;%Y-%m-%d %H:%M:%S&quot;) # Although we want to use solar time, let&#39;s add both incase you want to explore the implications img_locs$solar &lt;- tmp$solar img_locs$clock &lt;- tmp$clock We are now ready to fit some models! 12.3 Species comparisons Let’s start with a white-tailed deer and caribou example. Note we are reducing the number of replicates to 100 to speed up the process - typically people use 1000. # Fit an activity model to the WTD data m1 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Odocoileus.virginianus&quot;], sample=&quot;model&quot;, reps=100) #plot(m1) # Repeat for caribou # Fit an activity model m2 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Rangifer.tarandus&quot;], sample=&quot;model&quot;, reps=100) #plot(m2) # Plot the results of both on the same axis plot(m2, yunit=&quot;density&quot;, data=&quot;none&quot;, las=1, lwd=2, tline=list(lwd=2), # Thick line cline=list(lty=0)) # Supress confidence intervals plot(m1, yunit=&quot;density&quot;, data=&quot;none&quot;, add=TRUE, tline=list(col=&quot;red&quot;, lwd=2), cline=list(lty=0)) legend(&quot;topright&quot;, c(&quot;Caribou&quot;, &quot;Deer&quot;), col=1:2, lty=1, lwd=2) We can compare different activity patterns using coefficient of overlap (∆) - developed by Ridout and Linkie: Ridout, Martin S., and Matthew Linkie. “Estimating overlap of daily activity patterns from camera trap data.” Journal of Agricultural, Biological, and Environmental Statistics 14.3 (2009): 322-337. The coefficient ranges from 0 (no overlap) to 1 (complete overlap). We can implement for a two species comparison as follows: # Note reps reduced to speed up running time - people typically use 1000. compareCkern(m1, m2, reps = 100) ## obs null seNull pNull ## 0.78465241 0.95402374 0.01004905 0.00000000 The output above represents: 0 = no overlap and 1 = high overlap! obs = observed overlap index; null = mean null overlap index; seNull = standard error of the null distribution; pNull = probability observed index arose by chance. Which suggests there is reasonably high overlap between the two species - and that it did not come about by chance. 12.4 Treatment comparisons We can also compare patterns within a species across different strata of interest. For example, perhaps white-tailed deer change their activity patterns in response to the feature_type they are using - perhaps they will be more nocturnal on HumanUse lines relative to Offline strata. Lets try it: White-tail deer on HumanUse feature #Fit an activity model - human use lines m1 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Odocoileus.virginianus&quot; &amp; img_locs$feature_type==&quot;HumanUse&quot;], sample=&quot;model&quot;, reps=100) # Offline areas m2 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Odocoileus.virginianus&quot; &amp; img_locs$feature_type==&quot;Offline&quot;], sample=&quot;model&quot;, reps=100) plot(m2, yunit=&quot;density&quot;, data=&quot;none&quot;, las=1, lwd=2, tline=list(lwd=2), # Thick line cline=list(lty=0)) # Supress confidence intervals plot(m1, yunit=&quot;density&quot;, data=&quot;none&quot;, add=TRUE, tline=list(col=&quot;red&quot;, lwd=2), cline=list(lty=0)) legend(&quot;topright&quot;, c(&quot;Offline&quot;, &quot;HumanUse&quot;), col=1:2, lty=1, lwd=2) # Note reps reduced to speed up running time - people typically use 1000. compareCkern(m1, m2, reps = 100) ## obs null seNull pNull ## 0.82674255 0.96050228 0.01153082 0.00000000 There is very high overlap for these comparisons, and it is unlikely to have arisen by chance! So it seems the edidence for changes in temporal activity in response to feature_type is weak - at least for the white-tiled deer! 12.4.1 Seasonal comparison # Extract the month information img_locs$month &lt;- month(img_locs$timestamp, label=T) #Fit an activity model - using just the &#39;summer&#39; months m1 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Rangifer.tarandus&quot; &amp; img_locs$month %in% c(&quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;)], sample=&quot;model&quot;, reps=100) # Winter months m2 &lt;- fitact(img_locs$solar[img_locs$sp==&quot;Rangifer.tarandus&quot; &amp; img_locs$month %in% c(&quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;, &quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;)], sample=&quot;model&quot;, reps=100) plot(m2, yunit=&quot;density&quot;, data=&quot;none&quot;, las=1, lwd=2, tline=list(lwd=2), # Thick line cline=list(lty=0)) # Supress confidence intervals plot(m1, yunit=&quot;density&quot;, data=&quot;none&quot;, add=TRUE, tline=list(col=&quot;red&quot;, lwd=2), cline=list(lty=0)) legend(&quot;topright&quot;, c(&quot;Winter&quot;, &quot;Summer&quot;), col=1:2, lty=1, lwd=2) 12.5 Selected further reading Houngbégnon, Fructueux GA, et al. “Daily Activity Patterns and Co-Occurrence of Duikers Revealed by an Intensive Camera Trap Survey across Central African Rainforests.” Animals 10.12 (2020): 2200. Ross J, Hearn AJ, Johnson PJ, Macdonald DW (2013). Activity patterns and temporal avoidance by prey in response to Sunda clouded leopard predation risk. Journal of Zoology, 290(2), 96,106. Azevedo FC, Lemos FG, Freitas-Junior MC, Rocha DG, Azevedo FCC (2018). Puma activity patterns and temporal overlap with prey in a human-modifed landscape at Southeastern Brazil.” Journal of Zoology "],["density.html", "Chapter 13 Density 13.1 Individually identifiable individuals 13.2 Unmarked animals 13.3 Future directions", " Chapter 13 Density Precise and unbiased population density estimates are fundamental to conserve rare and vulnerable species… But it is complicated, especially with camera traps! There we said it, estimating density from camera trap data is not easy, often isn’t precise, and can require you to move beyond “just” R (typically JAGS or Nimble). Also - over the last few years the number of approaches has grown rapidly, consequently it is impossible to cover all of them here. There have been several great review papers published recently, and we recommend you check each one out: Morin, Dana J., et al. “Comparison of methods for estimating density and population trends for low-density Asian bears.” Global Ecology and Conservation 35 (2022): e02058. This paper is great for overview of the different methods available with a specific species in mind - Asian black bear. They discuss the methods, and do not directly compare them. Gilbert, N. A., Clare, J. D., Stenglein, J. L., &amp; Zuckerberg, B. (2021). Abundance estimation of unmarked animals based on camera‐trap data. Conservation Biology, 35(1), 88-100. This paper provides a nice overview of the state of the art of density estimation of unmarked animals. They discuss the methods, and do not directly compare them. Palencia, P., Rowcliffe, J. M., Vicente, J., &amp; Acevedo, P. (2021). Assessing the camera trap methodologies used to estimate density of unmarked populations. Journal of Applied Ecology, 58(8), 1583-1592. A quantitative comparison of different unmarked density estimators - focusing on REM, REST and Distance methods. 13.1 Individually identifiable individuals If you are dealing with a project with individually identifiable animals, you are in luck as there are some great resources created by Ian Durbach and David Borchers: https://www.scr-cameratrap.com/ and an amazing tool for helping you design your surveys called secrdesign. Spatial capture recapture is considered the gold standard in density estimation, you cannot get much better than this! 13.2 Unmarked animals Unfortunately, it is not possible to identify individual animals for the vast majority of species detected by camera traps. There are a growing number of analysis frameworks for unmarked animals, including: 13.2.1 Random encounter model The random encounter model is based on modelling the ‘random encounters’ between moving animals and stationary camera traps. It takes into account key variables that affect the encounter rate: the camera detection zone, defined by its radius and angle, the daily distance travelled by an animal in the population (a.k.a. day range) Parameters required [and how you might get them]: y = number of independent photo events [from our independent detections file] t - total survey effort [from our deployment data] v = average speed of animal movement [We could use telemetry, we could use speed derived from cameras] r = radius of camera detection zone [Could use field trials as these parameters can vary station to station] theta = angle of camera detection zone [Could use field trials as these parameters can vary station to station] We have speed data for moose and wolf in both winter and summer (derived from telemetery studies which occured close to our region of interest). So let’s compare density estimates between winter (Oct-Mar) and summer (Apr-Sep) between these two species. In our project we didn’t empirically measure the detection zone, so we will assume that these remain constant through time time and space. First, install the remBoot package to help us fit the REM model. #devtools::install_github(&quot;arcaravaggi/remBoot&quot;) library(remBoot); library(dplyr); library(lubridate) 13.2.1.1 Formatting The formulation of the REM included in the ‘remBoot’ package is fairly simple, a dataframe consisting of rows, there each row is an independent detection, and with columns reflecting the strata of interest (confusingly labeled site), location_id (labelled cam), the group_size (labelled count), the viewshed radius (in km) and the viewshed angle (width) in radians. Note: in this instance, we don’t have empirically derived measures of the viewshed radius and angle, so we will use the values assessed by TrailCameraPro by Reconyx for the Hyperfire 2 (the camera model used in this study): angle = 42.9; and half the maximum distance for its range = 25m . We can easily derive this from our independent detections data frame. Moose first! 13.2.2 Moose From existing literature, we are expecting moose densities of roughly 0.2-0.5 individuals per km2. ind &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_detections.csv&quot;, header=T) # Setup a winter and summer months variable summer &lt;- c(&quot;04&quot;, &quot;05&quot;, &quot;06&quot;, &quot;07&quot;, &quot;08&quot;, &quot;09&quot;) winter &lt;- c(&quot;01&quot;, &quot;02&quot;, &quot;03&quot;, &quot;10&quot;, &quot;11&quot;, &quot;12&quot;) # Subset to moose (alces alces) and the summer months moose_summer &lt;- ind[ind$sp==&quot;Alces.alces&quot; &amp; substr(ind$timestamp,6,7) %in% summer,c(&quot;placename&quot;, &quot;event_groupsize&quot;)] # rename the columns moose_summer &lt;- moose_summer %&gt;% rename(&quot;cam&quot;=placename, &quot;count&quot;=event_groupsize) moose_summer$dist &lt;- 0.024 # Our detection distance in km moose_summer$theta &lt;- 42.9*(pi/180) # Our viewshed angle # Subset to moose (alces alces) and the winter months moose_winter &lt;- ind[ind$sp==&quot;Alces.alces&quot; &amp; substr(ind$timestamp,6,7) %in% winter,c(&quot;placename&quot;, &quot;event_groupsize&quot;)] # rename the columns moose_winter &lt;- moose_winter %&gt;% rename(&quot;cam&quot;=placename, &quot;count&quot;=event_groupsize) # Add the detection zone covariates moose_winter$dist &lt;- 0.024 moose_winter$theta &lt;- 42.9*(pi/180) # The the monthly data to get an effort estimate for each season mon_obs &lt;- read.csv(&quot;data/processed_data/AlgarRestorationProject_30min_independent_monthly_observations.csv&quot;, header=T) # Sum the values summer_effort &lt;- sum(mon_obs$days[substr(mon_obs$date, 6,7) %in% summer]) winter_effort &lt;- sum(mon_obs$days[substr(mon_obs$date, 6,7) %in% winter]) Here I will use the average daily distance for summer and winter derived from telemetry datasets on Movebank from locations close to where this camera trap study was conducted: Moose winter = 1.07 km per day Moose summer = 1.15 km per day Now lets fit the REM model. # Number of iterations nboots &lt;- 1000 summer_rem &lt;- rem(dat = moose_summer, tm=summer_effort, v=1.15) winter_rem &lt;- rem(dat = moose_winter, tm=winter_effort, v=1.07) moose_res &lt;- data.frame(season=c(&quot;summer&quot;, &quot;winter&quot;), species=&quot;moose&quot;, density=c(summer_rem,winter_rem), sd=NA) # Add the sd tm &lt;- summer_effort v &lt;- 1.15 moose_res$sd[moose_res$season==&quot;summer&quot;] &lt;- sd(boot_sd(moose_summer)) tm &lt;- winter_effort v &lt;- 1.07 moose_res$sd[moose_res$season==&quot;winter&quot;] &lt;- sd(boot_sd(moose_winter)) # Look at the results moose_res ## season species density sd ## 1 summer moose 0.5275170 0.02045190 ## 2 winter moose 0.4094503 0.02908781 Remember, we were expecting a density of around 0.2 to 0.5 individuals per km2… not bad! Lets make a plot of the estimated densities and their standard deviations: library(ggplot2) p&lt;-ggplot(moose_res, aes(x=season, y=density)) + geom_point()+ geom_errorbar(aes(ymin=density-sd, ymax=density+sd), width=.2, position=position_dodge(0.05)) + theme_classic() p 13.2.3 Wolf From existing literature we would expect wolf densities of 0.001 - 0.025 individuals per km2. Lets repeat our analysis for wolves: # Subset to moose (alces alces) and the summer months wolf_summer &lt;- ind[ind$sp==&quot;Canis.lupus&quot; &amp; substr(ind$timestamp,6,7) %in% summer,c(&quot;placename&quot;, &quot;event_groupsize&quot;)] # rename the columns wolf_summer &lt;- wolf_summer %&gt;% rename(&quot;cam&quot;=placename, &quot;count&quot;=event_groupsize) wolf_summer$dist &lt;- 0.024 # Our detection distance in km wolf_summer$theta &lt;- 42.9*(pi/180) # Our viewshed angle # Subset to wolf (alces alces) and the winter months wolf_winter &lt;- ind[ind$sp==&quot;Canis.lupus&quot; &amp; substr(ind$timestamp,6,7) %in% winter,c(&quot;placename&quot;, &quot;event_groupsize&quot;)] # rename the columns wolf_winter &lt;- wolf_winter %&gt;% rename(&quot;cam&quot;=placename, &quot;count&quot;=event_groupsize) # Add the detection zone covariates wolf_winter$dist &lt;- 0.024 wolf_winter$theta &lt;- 42.9*(pi/180) summer_rem &lt;- rem(dat = wolf_summer, tm=summer_effort, v=11.9) winter_rem &lt;- rem(dat = wolf_winter, tm=winter_effort, v=11.8) wolf_res &lt;- data.frame(season=c(&quot;summer&quot;, &quot;winter&quot;), species=&quot;wolf&quot;, density=c(summer_rem,winter_rem), sd=NA) # Add the sd tm &lt;- summer_effort v &lt;- 11.9 wolf_res$sd[wolf_res$season==&quot;summer&quot;] &lt;- sd(boot_sd(wolf_summer)) tm &lt;- winter_effort v &lt;- 11.8 wolf_res$sd[wolf_res$season==&quot;winter&quot;] &lt;- sd(boot_sd(wolf_winter)) Which again, is fairly close to our expected densities, if a little on the high side. Again let’s plot them: library(ggplot2) p&lt;-ggplot(wolf_res, aes(x=season, y=density)) + geom_point()+ geom_errorbar(aes(ymin=density-sd, ymax=density+sd), width=.2, position=position_dodge(0.05)) + theme_classic() p These estimates are in the right ball park - and suggesting that wolf densities are higher in winter. The reference for the movement data use to calculate the movement speeds are: Wolves: Latham ADM, Boutin S. 2019. Data from: Wolf ecology and caribou-primary prey-wolf spatial relationships in low productivity peatland complexes in northeastern Alberta. Movebank Data Repository. Moose: Bohm H, Neilson E, de la Mare C, Boutin S (2014) Wildlife habitat effectiveness and connectivity: moose ecology project summary report 2010–2012: Final report. 41 p. 13.3 Future directions Direct comparisons of the different methods are starting to appear: Santini, Giacomo, et al. “Population assessment without individual identification using camera-traps: A comparison of four methods.” Basic and Applied Ecology 61 (2022): 68-81. “Further, while unmarked methods require less information and model parameters, there is far greater risk of bias in estimates resulting from model assumptions that are difficult to validate. The inconsistencies in precision of unmarked empirical estimates, even within the same study designs, sites, and species (Table 3), likely demonstrate unaccounted assumption violations pertaining to animal movement and we would expect these issues to extend to most Asian bear populations.” The future of determining viewshed area: Moeller, Anna K., et al. “Best practices to account for capture probability and viewable area in camera‐based abundance estimation.” Remote Sensing in Ecology and Conservation (2022). Nice way of estimating “day range” from camera traps which is equivalent to telemetry data Palencia, Pablo, et al. “Estimating day range from camera‐trap data: the animals’ behaviour as a key parameter.” Journal of Zoology 309.3 (2019): 182-190. And Pablo Palencia has a nice package to help you integrate speed data derived from cameras with activity data derived from camera traps in the activity package. See the Activity chapter! trappingmotion "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
